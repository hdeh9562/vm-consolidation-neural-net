{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consolidation with DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGosssip-based virual machine consolidation in a cloud environment.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gosssip-based virual machine consolidation in a cloud environment.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load depenedancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsolidationEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        A datacenter has many virtual machines(VM). VMs need to get consolidated into some of the physical machines so some otheer physical machines can be turned off.\n",
    "    Source:\n",
    "        This environment corresponds to gosssip-based VM consolidation\n",
    "    Observation: \n",
    "        Type: Box(2)\n",
    "        Num\tObservation                 Min         Max\n",
    "        0\tCPU Utilization            0.0            100.0\n",
    "        1\tMemory Utilization         0.0            100.0\n",
    "        \n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num\tAction\n",
    "        0\tLow \n",
    "        1\tMedium\n",
    "        2\tHigh\n",
    "        3\txHigh\n",
    "        4\t2xHigh\n",
    "        5\t3xHigh\n",
    "        6\t4xhigh\n",
    "        7\t5xHigh\n",
    "        8\tOverload\n",
    "        \n",
    "        \n",
    "    Rewards-out:\n",
    "        In sender mode, rewards are given to a PM to move out its VMs so that it can switch off\n",
    "        Level\tReward\n",
    "        0\t1000\n",
    "        1\t900\n",
    "        2\t800\n",
    "        3\t700\n",
    "        4\t600\n",
    "        5\t500\n",
    "        6\t400\n",
    "        7\t300\n",
    "        8\t200\n",
    "        \n",
    "    Rewards-in:\n",
    "        In recipient mode, rewards are given to avoid SLA violation. It occurs when a PM moves to an overload state\n",
    "        Level\tReward\n",
    "        0\t100\n",
    "        1\t100\n",
    "        2\t100\n",
    "        3\t100\n",
    "        4\t100\n",
    "        5\t100\n",
    "        6\t100\n",
    "        7\t100\n",
    "        8\t-2000\n",
    "        \n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value between 0,100\n",
    "    Episode Termination:\n",
    "        Pole Angle is more than ±12°\n",
    "        Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\n",
    "        Episode length is greater than 200\n",
    "        Solved Requirements\n",
    "        Considered solved when the average reward is greater than or equal to 195.0 over 100 consecutive trials.\n",
    "    \"\"\"\n",
    "    \n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second' : 50\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = (self.masspole + self.masscart)\n",
    "        self.length = 0.5 # actually half the pole's length\n",
    "        self.polemass_length = (self.masspole * self.length)\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = 'euler'\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.cpu_min_utilization = 0.0\n",
    "        self.cpu_max_utilization = 100.0\n",
    "        self.memory_min_utilization = 0.0\n",
    "        self.memory_max_utilization = 100.0\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation is still within bounds\n",
    "        low = np.array([\n",
    "            self.cpu_min_utilization,\n",
    "            self.memory_min_utilization])\n",
    "        \n",
    "        high = np.array([\n",
    "            self.cpu_max_utilization,\n",
    "            self.memory_max_utilization])\n",
    "\n",
    "        self.action_space = spaces.Discrete(9) # actions\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32) # states\n",
    "        \n",
    "        self.reward_out = {\n",
    "            0 : 1000,\n",
    "            1 : 900,\n",
    "            2 : 800,\n",
    "            3 : 700,\n",
    "            4 : 600,\n",
    "            5 : 500,\n",
    "            6 : 400,\n",
    "            7 : 300,\n",
    "            8 : 200\n",
    "        }\n",
    "        \n",
    "        self.reward_in = {\n",
    "            0 : 100,\n",
    "            1 : 100,\n",
    "            2 : 100,\n",
    "            3 : 100,\n",
    "            4 : 100,\n",
    "            5 : 100,\n",
    "            6 : 100,\n",
    "            7 : 100,\n",
    "            8 : -2000\n",
    "        }\n",
    "        print(\"Reward {}\".format(self.reward_out))\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\"%(action, type(action))\n",
    "        state = self.state\n",
    "        x, x_dot, theta, theta_dot = state\n",
    "        force = self.force_mag if action==1 else -self.force_mag\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "        temp = (force + self.polemass_length * theta_dot * theta_dot * sintheta) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta* temp) / (self.length * (4.0/3.0 - self.masspole * costheta * costheta / self.total_mass))\n",
    "        xacc  = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "        if self.kinematics_integrator == 'euler':\n",
    "            x  = x + self.tau * x_dot\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "        else: # semi-implicit euler\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            x  = x + self.tau * x_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "        self.state = (x,x_dot,theta,theta_dot)\n",
    "        done =  x < -self.x_threshold \\\n",
    "                or x > self.x_threshold \\\n",
    "                or theta < -self.theta_threshold_radians \\\n",
    "                or theta > self.theta_threshold_radians\n",
    "        done = bool(done)\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_done == 0:\n",
    "                logger.warn(\"You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\")\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return np.array(self.state), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=0.0, high=100.0, size=(2,))\n",
    "        self.steps_beyond_done = None\n",
    "        return np.array(self.state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward {0: 1000, 1: 900, 2: 800, 3: 700, 4: 600, 5: 500, 6: 400, 7: 300, 8: 200}\n"
     ]
    }
   ],
   "source": [
    "env = ConsolidationEnv() # initialise environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_size = env.observation_space.shape[0]\n",
    "state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_size = env.action_space.n\n",
    "action_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 1000 # n games we want agen to play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_outpu/cartpole/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgentSender:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000) # double-ended queue for sender mode memory; acts like list, but elements can be added/removed from either end\n",
    "        self.gamma = 0.95 # decay or discount rate: enables agent to take into account future actions in addition to the immediate ones, but discounted at this rate\n",
    "        self.epsilon = 1.0 # exploration rate: how much to act randomly; more initially than later due to epsilon decay\n",
    "        self.epsilon_decay = 0.995 # decrease number of random explorations as the agent's performance (hopefully) improves over time\n",
    "        self.epsilon_min = 0.01 # minimum amount of random exploration permitted\n",
    "        self.learning_rate = 0.001 # rate at which NN adjusts models parameters via SGD to reduce cost \n",
    "        self.model = self._build_model() # private method \n",
    "    \n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu')) # 1st hidden layer; states as input\n",
    "        model.add(Dense(24, activation='relu')) # 2nd hidden layer\n",
    "        model.add(Dense(self.action_size, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # list of previous experiences, enabling re-training later\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon: # if acting randomly, take random action\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state) # if not acting randomly, predict reward value based on current state\n",
    "        return np.argmax(act_values[0]) # pick the action that will give the highest reward (i.e., go left or right?)\n",
    "\n",
    "    def replay(self, batch_size): # method that trains NN with experiences sampled from memory\n",
    "        minibatch = random.sample(self.memory, batch_size) # sample a minibatch from memory\n",
    "        for state, action, reward, next_state, done in minibatch: # extract data for each minibatch sample\n",
    "            target = reward # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward\n",
    "            if not done: # if not done, then predict future discounted reward\n",
    "                target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n",
    "                          np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n",
    "            target_f = self.model.predict(state) # approximately map current state to future discounted reward\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0) # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgentRecipient:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000) # double-ended queue for sender mode memory; acts like list, but elements can be added/removed from either end\n",
    "        self.gamma = 0.95 # decay or discount rate: enables agent to take into account future actions in addition to the immediate ones, but discounted at this rate\n",
    "        self.epsilon = 1.0 # exploration rate: how much to act randomly; more initially than later due to epsilon decay\n",
    "        self.epsilon_decay = 0.995 # decrease number of random explorations as the agent's performance (hopefully) improves over time\n",
    "        self.epsilon_min = 0.01 # minimum amount of random exploration permitted\n",
    "        self.learning_rate = 0.001 # rate at which NN adjusts models parameters via SGD to reduce cost \n",
    "        self.model = self._build_model() # private method \n",
    "    \n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu')) # 1st hidden layer; states as input\n",
    "        model.add(Dense(24, activation='relu')) # 2nd hidden layer\n",
    "        model.add(Dense(self.action_size, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # list of previous experiences, enabling re-training later\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon: # if acting randomly, take random action\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state) # if not acting randomly, predict reward value based on current state\n",
    "        return np.argmax(act_values[0]) # pick the action that will give the highest reward (i.e., go left or right?)\n",
    "\n",
    "    def replay(self, batch_size): # method that trains NN with experiences sampled from memory\n",
    "        minibatch = random.sample(self.memory, batch_size) # sample a minibatch from memory\n",
    "        for state, action, reward, next_state, done in minibatch: # extract data for each minibatch sample\n",
    "            target = reward # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward\n",
    "            if not done: # if not done, then predict future discounted reward\n",
    "                target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n",
    "                          np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n",
    "            target_f = self.model.predict(state) # approximately map current state to future discounted reward\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0) # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_agent = DQNAgentSender(state_size, action_size) # initialise sender agent\n",
    "recipient_agent = DQNAgentRecipient(state_size, action_size) # initialise recipient agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/1000\n",
      "State[CPU, Memory] => [[49.30105211 71.6277584 ]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 1/1000\n",
      "State[CPU, Memory] => [[75.01307235 71.98909135]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 2/1000\n",
      "State[CPU, Memory] => [[72.00684591 89.1524487 ]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 3/1000\n",
      "State[CPU, Memory] => [[29.78692484 11.28682124]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 4/1000\n",
      "State[CPU, Memory] => [[19.32111101 64.79040249]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 5/1000\n",
      "State[CPU, Memory] => [[76.83592833 62.76008497]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 6/1000\n",
      "State[CPU, Memory] => [[69.55319736 85.94556595]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 7/1000\n",
      "State[CPU, Memory] => [[88.49322621 71.89693529]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 8/1000\n",
      "State[CPU, Memory] => [[41.69043703 81.63041252]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 9/1000\n",
      "State[CPU, Memory] => [[ 5.07059049 50.65917257]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 10/1000\n",
      "State[CPU, Memory] => [[39.2088505  63.75588929]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 11/1000\n",
      "State[CPU, Memory] => [[86.99953851  6.95231272]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 12/1000\n",
      "State[CPU, Memory] => [[11.91873315 86.52253044]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 13/1000\n",
      "State[CPU, Memory] => [[93.87768122  4.94210935]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 14/1000\n",
      "State[CPU, Memory] => [[ 3.83958634 27.88848137]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 15/1000\n",
      "State[CPU, Memory] => [[88.9760198  34.53268669]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 16/1000\n",
      "State[CPU, Memory] => [[29.22215355 51.02258388]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 17/1000\n",
      "State[CPU, Memory] => [[73.24877844 79.91297455]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 18/1000\n",
      "State[CPU, Memory] => [[48.4685415  37.56721951]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 19/1000\n",
      "State[CPU, Memory] => [[70.92899465 23.24087763]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 20/1000\n",
      "State[CPU, Memory] => [[44.77127136 34.41690716]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 21/1000\n",
      "State[CPU, Memory] => [[93.44616883 73.42734078]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 22/1000\n",
      "State[CPU, Memory] => [[46.57210974 29.61835865]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 23/1000\n",
      "State[CPU, Memory] => [[92.06578715 91.37825836]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 24/1000\n",
      "State[CPU, Memory] => [[49.97338399 98.4915317 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 25/1000\n",
      "State[CPU, Memory] => [[58.19287561  2.21016718]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 26/1000\n",
      "State[CPU, Memory] => [[19.49700309 32.80881465]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 27/1000\n",
      "State[CPU, Memory] => [[20.14129203 35.4450134 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 28/1000\n",
      "State[CPU, Memory] => [[ 2.80101072 67.15640872]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 29/1000\n",
      "State[CPU, Memory] => [[43.87076452 85.87301598]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 30/1000\n",
      "State[CPU, Memory] => [[ 7.43170649 57.53823854]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 31/1000\n",
      "State[CPU, Memory] => [[50.77206466 75.36545946]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 32/1000\n",
      "State[CPU, Memory] => [[69.14847829 86.73446567]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 33/1000\n",
      "State[CPU, Memory] => [[23.54382941 42.53452622]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 34/1000\n",
      "State[CPU, Memory] => [[80.57645741 35.88822624]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 35/1000\n",
      "State[CPU, Memory] => [[65.77527952 89.02730035]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 36/1000\n",
      "State[CPU, Memory] => [[49.66749142 40.28848677]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 37/1000\n",
      "State[CPU, Memory] => [[ 4.7113865 11.7488609]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 38/1000\n",
      "State[CPU, Memory] => [[91.17774888 18.79106938]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 39/1000\n",
      "State[CPU, Memory] => [[41.06063819  7.01885415]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 40/1000\n",
      "State[CPU, Memory] => [[65.38772309 46.77475016]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 41/1000\n",
      "State[CPU, Memory] => [[10.33879154 10.51385494]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 42/1000\n",
      "State[CPU, Memory] => [[91.48267996 54.59159276]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 43/1000\n",
      "State[CPU, Memory] => [[63.58216297 18.09144462]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 44/1000\n",
      "State[CPU, Memory] => [[34.62714351 25.36672857]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 45/1000\n",
      "State[CPU, Memory] => [[5.04688655 4.75513328]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 46/1000\n",
      "State[CPU, Memory] => [[37.17196686 58.06238388]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 47/1000\n",
      "State[CPU, Memory] => [[48.1846573   2.88121632]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 48/1000\n",
      "State[CPU, Memory] => [[50.98878042 56.46352888]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 49/1000\n",
      "State[CPU, Memory] => [[36.37906533 42.81058437]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 50/1000\n",
      "State[CPU, Memory] => [[26.09667085 80.89600049]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 51/1000\n",
      "State[CPU, Memory] => [[39.8859954   3.79739692]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 52/1000\n",
      "State[CPU, Memory] => [[31.08665452 86.65822362]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 53/1000\n",
      "State[CPU, Memory] => [[75.6641265  48.36777826]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 54/1000\n",
      "State[CPU, Memory] => [[42.34613949 77.14347764]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 55/1000\n",
      "State[CPU, Memory] => [[53.89426352 23.01792112]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 56/1000\n",
      "State[CPU, Memory] => [[99.08923703 48.2449074 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 57/1000\n",
      "State[CPU, Memory] => [[32.06341159 22.68317311]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 58/1000\n",
      "State[CPU, Memory] => [[57.28449579 51.36842103]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 59/1000\n",
      "State[CPU, Memory] => [[38.80504844 94.79906101]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 60/1000\n",
      "State[CPU, Memory] => [[29.14708232 32.61918913]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 61/1000\n",
      "State[CPU, Memory] => [[27.10123423 14.33873621]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 62/1000\n",
      "State[CPU, Memory] => [[19.89800516 38.81599525]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 63/1000\n",
      "State[CPU, Memory] => [[68.03348864 84.96344673]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 64/1000\n",
      "State[CPU, Memory] => [[27.27349623  0.34962794]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 65/1000\n",
      "State[CPU, Memory] => [[ 6.47951002 78.62473644]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 66/1000\n",
      "State[CPU, Memory] => [[81.97888589 35.99658657]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 67/1000\n",
      "State[CPU, Memory] => [[66.46542296 17.60812378]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 68/1000\n",
      "State[CPU, Memory] => [[74.12648573 34.90460193]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 69/1000\n",
      "State[CPU, Memory] => [[43.20246048 62.66546442]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 70/1000\n",
      "State[CPU, Memory] => [[49.23749605 22.56593082]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 71/1000\n",
      "State[CPU, Memory] => [[16.019513   11.70876869]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 72/1000\n",
      "State[CPU, Memory] => [[27.36978153  3.10342068]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 73/1000\n",
      "State[CPU, Memory] => [[39.36746873 20.89998069]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 74/1000\n",
      "State[CPU, Memory] => [[41.17647655  4.12031411]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 75/1000\n",
      "State[CPU, Memory] => [[85.11473107 53.01795343]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 76/1000\n",
      "State[CPU, Memory] => [[ 3.2038121  12.06301944]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 77/1000\n",
      "State[CPU, Memory] => [[24.59696089 52.82144008]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 78/1000\n",
      "State[CPU, Memory] => [[20.16878111 12.87922667]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 79/1000\n",
      "State[CPU, Memory] => [[78.14249804 17.28304514]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 80/1000\n",
      "State[CPU, Memory] => [[ 7.00209085 22.40140743]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 81/1000\n",
      "State[CPU, Memory] => [[22.69222827 20.31263645]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 82/1000\n",
      "State[CPU, Memory] => [[90.65814038 73.17931244]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 83/1000\n",
      "State[CPU, Memory] => [[91.51077624 71.67894804]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 84/1000\n",
      "State[CPU, Memory] => [[86.65732617 11.74717672]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 85/1000\n",
      "State[CPU, Memory] => [[16.06316972 84.79071838]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 86/1000\n",
      "State[CPU, Memory] => [[32.50854654 93.23051509]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 87/1000\n",
      "State[CPU, Memory] => [[24.78041569  5.03276264]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 88/1000\n",
      "State[CPU, Memory] => [[14.60427822 51.35855417]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 89/1000\n",
      "State[CPU, Memory] => [[ 7.53292763 99.36123058]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 90/1000\n",
      "State[CPU, Memory] => [[13.87314489 38.2971851 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 91/1000\n",
      "State[CPU, Memory] => [[75.44430838 31.25189208]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 92/1000\n",
      "State[CPU, Memory] => [[32.64497555 19.78197343]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 93/1000\n",
      "State[CPU, Memory] => [[80.97399841 49.6907652 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 94/1000\n",
      "State[CPU, Memory] => [[61.71422753  3.60820544]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 95/1000\n",
      "State[CPU, Memory] => [[70.49057419 85.88982944]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 96/1000\n",
      "State[CPU, Memory] => [[56.61250696 97.98778872]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 97/1000\n",
      "State[CPU, Memory] => [[ 1.36388498 86.54055544]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 98/1000\n",
      "State[CPU, Memory] => [[ 9.57223079 12.03728424]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 99/1000\n",
      "State[CPU, Memory] => [[80.036656 70.103493]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 100/1000\n",
      "State[CPU, Memory] => [[45.88360609 84.21023656]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 101/1000\n",
      "State[CPU, Memory] => [[4.76448769 9.24161029]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 102/1000\n",
      "State[CPU, Memory] => [[46.35665913 67.05834095]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 103/1000\n",
      "State[CPU, Memory] => [[73.09389031 31.02953494]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 104/1000\n",
      "State[CPU, Memory] => [[29.86443373 65.00633087]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 105/1000\n",
      "State[CPU, Memory] => [[97.94566946 19.29817906]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 106/1000\n",
      "State[CPU, Memory] => [[45.31350817 17.73633552]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 107/1000\n",
      "State[CPU, Memory] => [[50.92120487 44.45451495]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 108/1000\n",
      "State[CPU, Memory] => [[88.51534829  0.74403228]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 109/1000\n",
      "State[CPU, Memory] => [[79.47356683 80.55717115]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 110/1000\n",
      "State[CPU, Memory] => [[49.47356889 76.61354983]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 111/1000\n",
      "State[CPU, Memory] => [[24.53288405 38.72278814]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 112/1000\n",
      "State[CPU, Memory] => [[42.50236447 38.19668313]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 113/1000\n",
      "State[CPU, Memory] => [[ 0.52784964 62.18066496]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 114/1000\n",
      "State[CPU, Memory] => [[10.33699154 43.9312299 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 115/1000\n",
      "State[CPU, Memory] => [[79.29411319 79.00380993]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 116/1000\n",
      "State[CPU, Memory] => [[40.75253887  4.50053719]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 117/1000\n",
      "State[CPU, Memory] => [[56.52719736 13.43093178]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 118/1000\n",
      "State[CPU, Memory] => [[81.48671024 85.28931754]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 119/1000\n",
      "State[CPU, Memory] => [[87.70661872 58.95163471]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 120/1000\n",
      "State[CPU, Memory] => [[37.96140305 62.75695402]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 121/1000\n",
      "State[CPU, Memory] => [[89.71848719 86.59387323]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 122/1000\n",
      "State[CPU, Memory] => [[16.89460043 96.99377493]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 123/1000\n",
      "State[CPU, Memory] => [[63.89771522 76.56162128]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 124/1000\n",
      "State[CPU, Memory] => [[84.87075257 67.70479826]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 125/1000\n",
      "State[CPU, Memory] => [[19.32383663 73.43240893]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 126/1000\n",
      "State[CPU, Memory] => [[99.52049065 40.87915988]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 127/1000\n",
      "State[CPU, Memory] => [[57.34740416 80.84520599]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 128/1000\n",
      "State[CPU, Memory] => [[43.56321716 36.25024323]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 129/1000\n",
      "State[CPU, Memory] => [[19.24768862 20.98200952]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 130/1000\n",
      "State[CPU, Memory] => [[74.0035455  47.21998003]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 131/1000\n",
      "State[CPU, Memory] => [[88.60448678 62.26784508]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 132/1000\n",
      "State[CPU, Memory] => [[ 5.8586536  68.46949114]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 133/1000\n",
      "State[CPU, Memory] => [[57.84755721 51.15341395]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 134/1000\n",
      "State[CPU, Memory] => [[86.5656628  57.41552195]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 135/1000\n",
      "State[CPU, Memory] => [[17.20729967 39.34942317]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 136/1000\n",
      "State[CPU, Memory] => [[92.93944962  2.09622052]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 137/1000\n",
      "State[CPU, Memory] => [[80.54395475 26.66440659]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 138/1000\n",
      "State[CPU, Memory] => [[73.44688001 85.97932011]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 139/1000\n",
      "State[CPU, Memory] => [[53.37764627 52.8889861 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 140/1000\n",
      "State[CPU, Memory] => [[54.46684515 12.84448595]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 141/1000\n",
      "State[CPU, Memory] => [[68.02392032 42.14022523]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 142/1000\n",
      "State[CPU, Memory] => [[71.09528476 18.59715326]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 143/1000\n",
      "State[CPU, Memory] => [[28.6931603  52.47761545]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 144/1000\n",
      "State[CPU, Memory] => [[62.22457398 36.02927232]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 145/1000\n",
      "State[CPU, Memory] => [[98.09856456 45.38230658]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 146/1000\n",
      "State[CPU, Memory] => [[26.48792906 11.65250013]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 147/1000\n",
      "State[CPU, Memory] => [[15.46487306 96.12538043]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 148/1000\n",
      "State[CPU, Memory] => [[59.86612255 39.42323573]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 149/1000\n",
      "State[CPU, Memory] => [[42.61393462 94.92038903]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 150/1000\n",
      "State[CPU, Memory] => [[40.99050461  8.16471819]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 151/1000\n",
      "State[CPU, Memory] => [[60.70217165 61.30186127]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 152/1000\n",
      "State[CPU, Memory] => [[46.87183319 74.13715868]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 153/1000\n",
      "State[CPU, Memory] => [[71.5157193   1.63582347]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 154/1000\n",
      "State[CPU, Memory] => [[94.43991253 38.96902857]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 155/1000\n",
      "State[CPU, Memory] => [[66.78467039 76.83311377]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 156/1000\n",
      "State[CPU, Memory] => [[ 6.85862236 94.38085443]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 157/1000\n",
      "State[CPU, Memory] => [[39.64330641  5.78056308]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 158/1000\n",
      "State[CPU, Memory] => [[57.08449616 75.45685375]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 159/1000\n",
      "State[CPU, Memory] => [[61.25783027  4.31641022]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 160/1000\n",
      "State[CPU, Memory] => [[18.01044313 26.59262886]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 161/1000\n",
      "State[CPU, Memory] => [[68.94207485 21.90368296]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 162/1000\n",
      "State[CPU, Memory] => [[43.0071203  85.80931597]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 163/1000\n",
      "State[CPU, Memory] => [[13.89933481 16.26680289]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 164/1000\n",
      "State[CPU, Memory] => [[94.33340932 55.80471915]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 165/1000\n",
      "State[CPU, Memory] => [[96.35213001 48.21369192]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 166/1000\n",
      "State[CPU, Memory] => [[17.42241949 95.75784028]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 167/1000\n",
      "State[CPU, Memory] => [[23.84199551 44.10515786]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 168/1000\n",
      "State[CPU, Memory] => [[43.05352562 87.42238625]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 169/1000\n",
      "State[CPU, Memory] => [[42.4695288  44.24143452]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 170/1000\n",
      "State[CPU, Memory] => [[45.16427288 33.00401205]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 171/1000\n",
      "State[CPU, Memory] => [[70.97906802 16.91382049]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 172/1000\n",
      "State[CPU, Memory] => [[90.66962621 97.03022909]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 173/1000\n",
      "State[CPU, Memory] => [[91.65305802 21.88920911]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 174/1000\n",
      "State[CPU, Memory] => [[80.09712108 80.64101731]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 175/1000\n",
      "State[CPU, Memory] => [[69.6295945  12.59657441]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 176/1000\n",
      "State[CPU, Memory] => [[43.40701477 95.68346929]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 177/1000\n",
      "State[CPU, Memory] => [[ 5.99347231 10.34392738]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 178/1000\n",
      "State[CPU, Memory] => [[67.93989987 29.99404745]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 179/1000\n",
      "State[CPU, Memory] => [[81.3966989  50.98262511]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 180/1000\n",
      "State[CPU, Memory] => [[31.81433951 23.38332717]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 181/1000\n",
      "State[CPU, Memory] => [[59.18746774 15.7458659 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 182/1000\n",
      "State[CPU, Memory] => [[91.97629511 80.54338819]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 183/1000\n",
      "State[CPU, Memory] => [[74.46810913 89.17030828]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 184/1000\n",
      "State[CPU, Memory] => [[73.41301752 26.88415864]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 185/1000\n",
      "State[CPU, Memory] => [[34.87918985 99.53167154]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 186/1000\n",
      "State[CPU, Memory] => [[ 0.4996026  57.94851885]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 187/1000\n",
      "State[CPU, Memory] => [[61.78297754 57.68146252]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 188/1000\n",
      "State[CPU, Memory] => [[41.96345345 55.49175706]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 189/1000\n",
      "State[CPU, Memory] => [[21.96956657 95.3884006 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 190/1000\n",
      "State[CPU, Memory] => [[26.95555448 98.18891354]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 191/1000\n",
      "State[CPU, Memory] => [[40.7446749  59.98392991]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 192/1000\n",
      "State[CPU, Memory] => [[30.18735925 56.90457425]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 193/1000\n",
      "State[CPU, Memory] => [[90.96480008 63.75163282]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 194/1000\n",
      "State[CPU, Memory] => [[24.80011978 33.82572785]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 195/1000\n",
      "State[CPU, Memory] => [[48.74155156 50.02452725]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 196/1000\n",
      "State[CPU, Memory] => [[83.69336522 45.212493  ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 197/1000\n",
      "State[CPU, Memory] => [[43.82822868 38.41046869]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 198/1000\n",
      "State[CPU, Memory] => [[40.29010662 21.84172643]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 199/1000\n",
      "State[CPU, Memory] => [[59.79407572 46.79762684]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 200/1000\n",
      "State[CPU, Memory] => [[97.25633207 68.35507207]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 201/1000\n",
      "State[CPU, Memory] => [[2.30993203 7.98768869]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 202/1000\n",
      "State[CPU, Memory] => [[ 2.61763877 52.71927129]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 203/1000\n",
      "State[CPU, Memory] => [[43.3477845  89.68059013]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 204/1000\n",
      "State[CPU, Memory] => [[42.78739089 35.28070229]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 205/1000\n",
      "State[CPU, Memory] => [[47.35125737 72.05187874]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 206/1000\n",
      "State[CPU, Memory] => [[75.03550999 41.11510038]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 207/1000\n",
      "State[CPU, Memory] => [[79.51819675 81.00871203]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 208/1000\n",
      "State[CPU, Memory] => [[12.73688656 43.9740139 ]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 209/1000\n",
      "State[CPU, Memory] => [[18.65937184 29.48183566]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 210/1000\n",
      "State[CPU, Memory] => [[45.16637968 20.63612195]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 211/1000\n",
      "State[CPU, Memory] => [[78.14482621 70.10046757]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 212/1000\n",
      "State[CPU, Memory] => [[55.31908849 60.46297146]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 213/1000\n",
      "State[CPU, Memory] => [[85.87963053 98.09401957]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 214/1000\n",
      "State[CPU, Memory] => [[49.06748602  2.06243984]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 215/1000\n",
      "State[CPU, Memory] => [[69.68351623 36.99539072]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 216/1000\n",
      "State[CPU, Memory] => [[88.03501135 55.96158793]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 217/1000\n",
      "State[CPU, Memory] => [[91.62288427 34.15442264]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 218/1000\n",
      "State[CPU, Memory] => [[69.66683888 66.95424558]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 219/1000\n",
      "State[CPU, Memory] => [[31.86014098  2.55663473]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 220/1000\n",
      "State[CPU, Memory] => [[40.32807858 15.01400716]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 221/1000\n",
      "State[CPU, Memory] => [[66.96876046 36.88273181]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 222/1000\n",
      "State[CPU, Memory] => [[50.89292406 14.74656743]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 223/1000\n",
      "State[CPU, Memory] => [[38.31976215 29.63467334]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 224/1000\n",
      "State[CPU, Memory] => [[51.72882133 81.27313303]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 225/1000\n",
      "State[CPU, Memory] => [[78.21935415 54.52312236]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 226/1000\n",
      "State[CPU, Memory] => [[19.71672084 27.13862631]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 227/1000\n",
      "State[CPU, Memory] => [[11.48181832 28.88648829]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 228/1000\n",
      "State[CPU, Memory] => [[11.28269946  8.95674999]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 229/1000\n",
      "State[CPU, Memory] => [[52.77282106 90.54718775]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 230/1000\n",
      "State[CPU, Memory] => [[78.03969999 25.12107151]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 231/1000\n",
      "State[CPU, Memory] => [[63.7968112  29.33981926]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 232/1000\n",
      "State[CPU, Memory] => [[26.58605862 77.4716019 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 233/1000\n",
      "State[CPU, Memory] => [[31.82242633  5.27920268]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 234/1000\n",
      "State[CPU, Memory] => [[35.63594439 89.2617903 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 235/1000\n",
      "State[CPU, Memory] => [[36.50508466 99.1790439 ]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 236/1000\n",
      "State[CPU, Memory] => [[ 1.42626591 96.51333085]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 237/1000\n",
      "State[CPU, Memory] => [[ 5.9193299  53.58932253]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 238/1000\n",
      "State[CPU, Memory] => [[2.46192947 4.28885574]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 239/1000\n",
      "State[CPU, Memory] => [[84.45655122 12.898518  ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 240/1000\n",
      "State[CPU, Memory] => [[43.41482765 58.39010981]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 241/1000\n",
      "State[CPU, Memory] => [[56.50201362 33.25796529]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 242/1000\n",
      "State[CPU, Memory] => [[20.99206734 92.50979905]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 243/1000\n",
      "State[CPU, Memory] => [[64.297592   42.07043375]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 244/1000\n",
      "State[CPU, Memory] => [[87.25828563 46.06916082]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 245/1000\n",
      "State[CPU, Memory] => [[35.13957183 44.32152006]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 246/1000\n",
      "State[CPU, Memory] => [[73.20551825  5.18257899]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 247/1000\n",
      "State[CPU, Memory] => [[62.13871461 35.39571563]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 248/1000\n",
      "State[CPU, Memory] => [[72.20412564 31.01686918]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 249/1000\n",
      "State[CPU, Memory] => [[77.02934325  7.75925685]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 250/1000\n",
      "State[CPU, Memory] => [[74.95564961  2.0707968 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 251/1000\n",
      "State[CPU, Memory] => [[13.29581229 79.51923944]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 252/1000\n",
      "State[CPU, Memory] => [[95.44898046 60.3628935 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 253/1000\n",
      "State[CPU, Memory] => [[37.84915633 26.0668867 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 254/1000\n",
      "State[CPU, Memory] => [[11.83793786 19.99011821]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 255/1000\n",
      "State[CPU, Memory] => [[38.41247847 65.63203297]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 256/1000\n",
      "State[CPU, Memory] => [[10.43767371 69.0981137 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 257/1000\n",
      "State[CPU, Memory] => [[93.93884316 78.06702389]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 258/1000\n",
      "State[CPU, Memory] => [[93.35621142 96.74080991]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 259/1000\n",
      "State[CPU, Memory] => [[81.85506393 61.40034587]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 260/1000\n",
      "State[CPU, Memory] => [[85.54618548 90.77508307]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 261/1000\n",
      "State[CPU, Memory] => [[50.45414766 24.4056053 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 262/1000\n",
      "State[CPU, Memory] => [[98.02427569 16.18936429]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 263/1000\n",
      "State[CPU, Memory] => [[48.43998215 70.96150079]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 264/1000\n",
      "State[CPU, Memory] => [[77.35447144  4.28935768]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 265/1000\n",
      "State[CPU, Memory] => [[63.12391376 77.69560613]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 266/1000\n",
      "State[CPU, Memory] => [[68.47265255 74.12577362]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 267/1000\n",
      "State[CPU, Memory] => [[61.52749978 53.04704163]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 268/1000\n",
      "State[CPU, Memory] => [[15.81515454 60.71237603]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 269/1000\n",
      "State[CPU, Memory] => [[78.15246031  9.73583468]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 270/1000\n",
      "State[CPU, Memory] => [[51.83897713 40.38915657]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 271/1000\n",
      "State[CPU, Memory] => [[30.83960926 33.52588156]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 272/1000\n",
      "State[CPU, Memory] => [[12.95823641 75.77801025]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 273/1000\n",
      "State[CPU, Memory] => [[34.89476903 90.09350346]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 274/1000\n",
      "State[CPU, Memory] => [[81.87778936 68.96385199]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 275/1000\n",
      "State[CPU, Memory] => [[13.70869992 41.65986787]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 276/1000\n",
      "State[CPU, Memory] => [[ 4.22732759 86.65142366]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 277/1000\n",
      "State[CPU, Memory] => [[ 6.45998755 61.16996649]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 278/1000\n",
      "State[CPU, Memory] => [[50.48257936 17.64093839]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 279/1000\n",
      "State[CPU, Memory] => [[42.58478485 24.56596611]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 280/1000\n",
      "State[CPU, Memory] => [[52.53215743  7.44404216]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 281/1000\n",
      "State[CPU, Memory] => [[20.39768919 34.30955661]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 282/1000\n",
      "State[CPU, Memory] => [[59.17338551  8.53227508]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 283/1000\n",
      "State[CPU, Memory] => [[67.8825545   6.56784212]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 284/1000\n",
      "State[CPU, Memory] => [[44.17155721 48.29700358]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 285/1000\n",
      "State[CPU, Memory] => [[43.842294   63.55821837]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 286/1000\n",
      "State[CPU, Memory] => [[56.98570829 89.51358671]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 287/1000\n",
      "State[CPU, Memory] => [[71.27877131 64.85670478]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 288/1000\n",
      "State[CPU, Memory] => [[97.73058908 60.39643023]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 289/1000\n",
      "State[CPU, Memory] => [[20.159398   58.65684536]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 290/1000\n",
      "State[CPU, Memory] => [[64.78706422 63.45307848]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 291/1000\n",
      "State[CPU, Memory] => [[21.17716146 91.92987361]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 292/1000\n",
      "State[CPU, Memory] => [[71.77629584 19.11076746]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 293/1000\n",
      "State[CPU, Memory] => [[93.09244851 66.66825003]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 294/1000\n",
      "State[CPU, Memory] => [[99.75753606 96.25763991]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 295/1000\n",
      "State[CPU, Memory] => [[87.79254364 29.19612792]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 296/1000\n",
      "State[CPU, Memory] => [[54.80949717  9.3888151 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 297/1000\n",
      "State[CPU, Memory] => [[58.11822097 29.63589158]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 298/1000\n",
      "State[CPU, Memory] => [[52.83855311 19.84676518]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 299/1000\n",
      "State[CPU, Memory] => [[99.83502371 67.18941272]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 300/1000\n",
      "State[CPU, Memory] => [[20.7649101  18.07848825]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 301/1000\n",
      "State[CPU, Memory] => [[83.59509459 15.6815487 ]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 302/1000\n",
      "State[CPU, Memory] => [[67.66852055 36.45344318]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 303/1000\n",
      "State[CPU, Memory] => [[58.49558686 13.54262344]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 304/1000\n",
      "State[CPU, Memory] => [[40.68706066 69.34047231]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 305/1000\n",
      "State[CPU, Memory] => [[52.92037879 99.06071057]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 306/1000\n",
      "State[CPU, Memory] => [[61.68673918 18.02567853]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 307/1000\n",
      "State[CPU, Memory] => [[91.4091715   5.97773938]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 308/1000\n",
      "State[CPU, Memory] => [[15.61177614 64.21223336]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 309/1000\n",
      "State[CPU, Memory] => [[78.39483008 98.73428458]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 310/1000\n",
      "State[CPU, Memory] => [[43.63173317 89.44337726]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 311/1000\n",
      "State[CPU, Memory] => [[45.43639701 53.14184778]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 312/1000\n",
      "State[CPU, Memory] => [[ 0.68254661 94.97110655]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 313/1000\n",
      "State[CPU, Memory] => [[55.72257169 73.45800821]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 314/1000\n",
      "State[CPU, Memory] => [[22.09317362 85.03566837]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 315/1000\n",
      "State[CPU, Memory] => [[ 6.34595665 54.96643355]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 316/1000\n",
      "State[CPU, Memory] => [[38.44983779 73.37474666]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 317/1000\n",
      "State[CPU, Memory] => [[66.04475145 28.40941409]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 318/1000\n",
      "State[CPU, Memory] => [[67.90917634 56.78334676]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 319/1000\n",
      "State[CPU, Memory] => [[29.75131058 82.53216019]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 320/1000\n",
      "State[CPU, Memory] => [[81.10598783 88.09635922]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 321/1000\n",
      "State[CPU, Memory] => [[ 9.63484984 79.37503545]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 322/1000\n",
      "State[CPU, Memory] => [[27.70206817 95.09694092]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 323/1000\n",
      "State[CPU, Memory] => [[77.00582151 89.26125894]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 324/1000\n",
      "State[CPU, Memory] => [[85.25462063 52.30030922]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 325/1000\n",
      "State[CPU, Memory] => [[50.53011411 15.84941674]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 326/1000\n",
      "State[CPU, Memory] => [[96.88405838 88.79526975]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 327/1000\n",
      "State[CPU, Memory] => [[ 6.84937427 90.50138528]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 328/1000\n",
      "State[CPU, Memory] => [[18.53439725 75.92280746]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 329/1000\n",
      "State[CPU, Memory] => [[73.37308001 68.58782032]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 330/1000\n",
      "State[CPU, Memory] => [[ 6.26765133 57.27826565]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 331/1000\n",
      "State[CPU, Memory] => [[64.83961939 86.41667966]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 332/1000\n",
      "State[CPU, Memory] => [[44.60997571 35.06113941]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 333/1000\n",
      "State[CPU, Memory] => [[11.30224256  6.75420069]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 334/1000\n",
      "State[CPU, Memory] => [[92.86042298 91.31923298]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 335/1000\n",
      "State[CPU, Memory] => [[71.00053519 14.33139929]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 336/1000\n",
      "State[CPU, Memory] => [[98.11085622 17.25535127]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 337/1000\n",
      "State[CPU, Memory] => [[86.41790927 26.84946959]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 338/1000\n",
      "State[CPU, Memory] => [[48.08956062 67.25653365]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 339/1000\n",
      "State[CPU, Memory] => [[52.49722335 63.42316549]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 340/1000\n",
      "State[CPU, Memory] => [[ 3.85091232 23.12767191]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 341/1000\n",
      "State[CPU, Memory] => [[17.94843421 62.17618556]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 342/1000\n",
      "State[CPU, Memory] => [[11.7598002  37.32781305]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 343/1000\n",
      "State[CPU, Memory] => [[22.15583699 46.47052819]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 344/1000\n",
      "State[CPU, Memory] => [[98.91889404 91.88926645]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 345/1000\n",
      "State[CPU, Memory] => [[46.33733815 92.38150339]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 346/1000\n",
      "State[CPU, Memory] => [[52.7106359  49.25175057]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 347/1000\n",
      "State[CPU, Memory] => [[81.59260025 63.412417  ]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 348/1000\n",
      "State[CPU, Memory] => [[89.09150666 56.46662634]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 349/1000\n",
      "State[CPU, Memory] => [[44.80243995  3.28931187]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 350/1000\n",
      "State[CPU, Memory] => [[28.65018835 33.16623069]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 351/1000\n",
      "State[CPU, Memory] => [[98.62631738  2.81904962]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 352/1000\n",
      "State[CPU, Memory] => [[68.4312338  73.70912324]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 353/1000\n",
      "State[CPU, Memory] => [[91.05761129 16.34407276]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 354/1000\n",
      "State[CPU, Memory] => [[53.87078243 12.96883626]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 355/1000\n",
      "State[CPU, Memory] => [[51.65522552 49.70796191]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 356/1000\n",
      "State[CPU, Memory] => [[95.85070786 56.81982735]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 357/1000\n",
      "State[CPU, Memory] => [[43.81874743 35.55053353]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 358/1000\n",
      "State[CPU, Memory] => [[61.3559479  47.81052932]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 359/1000\n",
      "State[CPU, Memory] => [[84.67931767 48.20984985]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 360/1000\n",
      "State[CPU, Memory] => [[54.90666667 34.69290674]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 361/1000\n",
      "State[CPU, Memory] => [[48.69838581 87.40170705]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 362/1000\n",
      "State[CPU, Memory] => [[66.90446138 68.86381386]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 363/1000\n",
      "State[CPU, Memory] => [[84.62341416 38.6573357 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 364/1000\n",
      "State[CPU, Memory] => [[54.72601146 52.93874591]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 365/1000\n",
      "State[CPU, Memory] => [[8.24826109 7.62469582]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 366/1000\n",
      "State[CPU, Memory] => [[98.93201847  8.85368926]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 367/1000\n",
      "State[CPU, Memory] => [[97.01502648 68.0644511 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 368/1000\n",
      "State[CPU, Memory] => [[14.83846576 12.13079483]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 369/1000\n",
      "State[CPU, Memory] => [[70.86251393 80.98705221]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 370/1000\n",
      "State[CPU, Memory] => [[93.54400657  2.34476049]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 371/1000\n",
      "State[CPU, Memory] => [[38.7367718  99.40619768]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 372/1000\n",
      "State[CPU, Memory] => [[9.99483186 6.88840937]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 373/1000\n",
      "State[CPU, Memory] => [[63.04676798  8.09046761]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 374/1000\n",
      "State[CPU, Memory] => [[84.75037041 39.93916582]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 375/1000\n",
      "State[CPU, Memory] => [[12.44673385  1.71617234]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 376/1000\n",
      "State[CPU, Memory] => [[66.24063165 60.17114229]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 377/1000\n",
      "State[CPU, Memory] => [[99.20806233 42.17608989]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 378/1000\n",
      "State[CPU, Memory] => [[58.59728355 81.22750948]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 379/1000\n",
      "State[CPU, Memory] => [[48.54373494 54.09283785]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 380/1000\n",
      "State[CPU, Memory] => [[14.59188102 84.03950453]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 381/1000\n",
      "State[CPU, Memory] => [[97.42344582 75.18333439]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 382/1000\n",
      "State[CPU, Memory] => [[96.06440797 94.66218998]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 383/1000\n",
      "State[CPU, Memory] => [[12.2118697  49.91422462]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 384/1000\n",
      "State[CPU, Memory] => [[84.18715709 99.95741074]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 385/1000\n",
      "State[CPU, Memory] => [[79.53824048 30.34251248]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 386/1000\n",
      "State[CPU, Memory] => [[63.76253514 73.91729689]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 387/1000\n",
      "State[CPU, Memory] => [[ 4.57098556 37.8417201 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 388/1000\n",
      "State[CPU, Memory] => [[79.58431186 67.9999639 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 389/1000\n",
      "State[CPU, Memory] => [[60.51110701 17.23713199]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 390/1000\n",
      "State[CPU, Memory] => [[49.12490312 97.79122455]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 391/1000\n",
      "State[CPU, Memory] => [[ 3.67546897 54.07704184]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 392/1000\n",
      "State[CPU, Memory] => [[31.35234363 52.54601592]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 393/1000\n",
      "State[CPU, Memory] => [[69.45226345 80.7060847 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 394/1000\n",
      "State[CPU, Memory] => [[74.86432389 90.76958483]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 395/1000\n",
      "State[CPU, Memory] => [[ 1.68148744 34.06919953]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 396/1000\n",
      "State[CPU, Memory] => [[65.88158755 53.55164829]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 397/1000\n",
      "State[CPU, Memory] => [[76.39565186  6.06988409]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 398/1000\n",
      "State[CPU, Memory] => [[19.39206738 94.16314838]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 399/1000\n",
      "State[CPU, Memory] => [[51.25440838 53.9088567 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 400/1000\n",
      "State[CPU, Memory] => [[99.83408787 39.74539585]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 401/1000\n",
      "State[CPU, Memory] => [[43.40973038 16.57208928]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 402/1000\n",
      "State[CPU, Memory] => [[48.2534377  66.70925373]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 403/1000\n",
      "State[CPU, Memory] => [[17.26823492 45.88461714]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 404/1000\n",
      "State[CPU, Memory] => [[58.95824283 72.41899713]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 405/1000\n",
      "State[CPU, Memory] => [[60.40558312 71.03856054]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 406/1000\n",
      "State[CPU, Memory] => [[23.22550195 66.41455856]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 407/1000\n",
      "State[CPU, Memory] => [[40.36472014  0.33496389]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 408/1000\n",
      "State[CPU, Memory] => [[71.77260084 16.65228825]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 409/1000\n",
      "State[CPU, Memory] => [[35.78138798 11.39192857]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 410/1000\n",
      "State[CPU, Memory] => [[15.3116642  92.90719661]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 411/1000\n",
      "State[CPU, Memory] => [[37.91535141 38.99153981]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 412/1000\n",
      "State[CPU, Memory] => [[40.29700481 18.24307502]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 413/1000\n",
      "State[CPU, Memory] => [[96.94659352 53.76170123]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 414/1000\n",
      "State[CPU, Memory] => [[54.37365083 62.31241499]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 415/1000\n",
      "State[CPU, Memory] => [[35.41672279 24.0198268 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 416/1000\n",
      "State[CPU, Memory] => [[34.73554253  8.93818097]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 417/1000\n",
      "State[CPU, Memory] => [[28.47227258 11.95842123]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 418/1000\n",
      "State[CPU, Memory] => [[90.13521814 63.95648089]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 419/1000\n",
      "State[CPU, Memory] => [[18.92275368 20.61603509]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 420/1000\n",
      "State[CPU, Memory] => [[26.63802413 91.22430575]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 421/1000\n",
      "State[CPU, Memory] => [[85.27654542 63.68423703]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 422/1000\n",
      "State[CPU, Memory] => [[28.50232357 85.70745425]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 423/1000\n",
      "State[CPU, Memory] => [[66.89192668 67.53811657]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 424/1000\n",
      "State[CPU, Memory] => [[95.9148036  93.67021195]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 425/1000\n",
      "State[CPU, Memory] => [[47.17654445 93.92191541]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 426/1000\n",
      "State[CPU, Memory] => [[38.26223318 89.98643594]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 427/1000\n",
      "State[CPU, Memory] => [[46.81608332 28.31437776]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 428/1000\n",
      "State[CPU, Memory] => [[ 5.89033971 96.46793494]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 429/1000\n",
      "State[CPU, Memory] => [[35.76537457  6.74500325]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 430/1000\n",
      "State[CPU, Memory] => [[37.6029961  71.42192246]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 431/1000\n",
      "State[CPU, Memory] => [[71.15478185 90.26973545]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 432/1000\n",
      "State[CPU, Memory] => [[55.74313817 60.91783372]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 433/1000\n",
      "State[CPU, Memory] => [[82.8678172  59.57002993]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 434/1000\n",
      "State[CPU, Memory] => [[90.64251787 53.6048163 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 435/1000\n",
      "State[CPU, Memory] => [[49.25583576 51.52565224]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 436/1000\n",
      "State[CPU, Memory] => [[35.13916152 75.17547908]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 437/1000\n",
      "State[CPU, Memory] => [[ 8.33300137 30.2557646 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 438/1000\n",
      "State[CPU, Memory] => [[32.40630293 42.64157449]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 439/1000\n",
      "State[CPU, Memory] => [[26.76913506 20.61678149]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 440/1000\n",
      "State[CPU, Memory] => [[17.00569472 69.52165475]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 441/1000\n",
      "State[CPU, Memory] => [[ 3.76309456 77.76182651]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 442/1000\n",
      "State[CPU, Memory] => [[10.68000039 99.28730384]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 443/1000\n",
      "State[CPU, Memory] => [[48.19247061 57.28802056]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 444/1000\n",
      "State[CPU, Memory] => [[95.15828594 47.86922841]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 445/1000\n",
      "State[CPU, Memory] => [[57.63885285 42.54679819]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 446/1000\n",
      "State[CPU, Memory] => [[64.84129518  6.9833887 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 447/1000\n",
      "State[CPU, Memory] => [[34.12647614 31.39018859]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 448/1000\n",
      "State[CPU, Memory] => [[84.32214914 57.18256352]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 449/1000\n",
      "State[CPU, Memory] => [[34.36474412 35.97963415]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 450/1000\n",
      "State[CPU, Memory] => [[20.14567329  7.87204977]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 451/1000\n",
      "State[CPU, Memory] => [[87.36328719 15.58596913]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 452/1000\n",
      "State[CPU, Memory] => [[40.1598503  16.42594385]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 453/1000\n",
      "State[CPU, Memory] => [[76.77020645 28.19233328]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 454/1000\n",
      "State[CPU, Memory] => [[90.37580801 35.83134016]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 455/1000\n",
      "State[CPU, Memory] => [[16.96560626 49.20335958]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 456/1000\n",
      "State[CPU, Memory] => [[21.41557057 39.68846219]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 457/1000\n",
      "State[CPU, Memory] => [[90.9083155  66.24854668]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 458/1000\n",
      "State[CPU, Memory] => [[65.30056477  1.97485797]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 459/1000\n",
      "State[CPU, Memory] => [[30.343821    4.44356383]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 460/1000\n",
      "State[CPU, Memory] => [[74.85588702 51.88338115]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 461/1000\n",
      "State[CPU, Memory] => [[87.96111725 65.59709072]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 462/1000\n",
      "State[CPU, Memory] => [[66.20953725 11.834796  ]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 463/1000\n",
      "State[CPU, Memory] => [[31.53809177 91.45580708]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 464/1000\n",
      "State[CPU, Memory] => [[21.8509268  46.77226956]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 465/1000\n",
      "State[CPU, Memory] => [[53.86904231 41.44574836]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 466/1000\n",
      "State[CPU, Memory] => [[25.42547044  4.54427165]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 467/1000\n",
      "State[CPU, Memory] => [[19.20673248 80.96300844]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 468/1000\n",
      "State[CPU, Memory] => [[82.39624067 77.70649172]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 469/1000\n",
      "State[CPU, Memory] => [[88.17777069 40.49778699]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 470/1000\n",
      "State[CPU, Memory] => [[57.94028322 37.59876324]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 471/1000\n",
      "State[CPU, Memory] => [[ 6.00866363 87.7829265 ]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 472/1000\n",
      "State[CPU, Memory] => [[74.62471072 10.97182417]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 473/1000\n",
      "State[CPU, Memory] => [[90.35111028 65.00960166]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 474/1000\n",
      "State[CPU, Memory] => [[59.61075151 14.50332999]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 475/1000\n",
      "State[CPU, Memory] => [[84.63503532 36.95855646]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 476/1000\n",
      "State[CPU, Memory] => [[31.70655416 60.28070679]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 477/1000\n",
      "State[CPU, Memory] => [[54.87489903 27.77517788]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 478/1000\n",
      "State[CPU, Memory] => [[72.48510219 39.37875206]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 479/1000\n",
      "State[CPU, Memory] => [[85.40299789 50.35012686]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 480/1000\n",
      "State[CPU, Memory] => [[34.30001128 47.02270476]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 481/1000\n",
      "State[CPU, Memory] => [[95.84839484 68.53843937]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 482/1000\n",
      "State[CPU, Memory] => [[49.8546301 17.8430738]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 483/1000\n",
      "State[CPU, Memory] => [[95.49610104 65.27525505]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 484/1000\n",
      "State[CPU, Memory] => [[56.73784565 91.21210629]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 485/1000\n",
      "State[CPU, Memory] => [[17.92869065  6.80643469]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 486/1000\n",
      "State[CPU, Memory] => [[ 2.65712521 15.03704158]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 487/1000\n",
      "State[CPU, Memory] => [[97.88704002 20.63737913]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 488/1000\n",
      "State[CPU, Memory] => [[81.61539753 48.86622987]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 489/1000\n",
      "State[CPU, Memory] => [[47.99652283 54.84427926]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 490/1000\n",
      "State[CPU, Memory] => [[93.70526093 72.53448832]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 491/1000\n",
      "State[CPU, Memory] => [[69.98765566 22.05968126]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 492/1000\n",
      "State[CPU, Memory] => [[88.4228616  12.07508601]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 493/1000\n",
      "State[CPU, Memory] => [[ 6.92120862 83.26664252]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 494/1000\n",
      "State[CPU, Memory] => [[ 6.89950828 25.78856343]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 495/1000\n",
      "State[CPU, Memory] => [[76.62164525 57.59645733]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 496/1000\n",
      "State[CPU, Memory] => [[92.78750533 80.78508322]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 497/1000\n",
      "State[CPU, Memory] => [[46.91660199  3.93874399]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 498/1000\n",
      "State[CPU, Memory] => [[85.66561576 29.82561295]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 499/1000\n",
      "State[CPU, Memory] => [[57.20622307  8.70593514]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 500/1000\n",
      "State[CPU, Memory] => [[12.70074685 68.07123674]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 501/1000\n",
      "State[CPU, Memory] => [[35.63579288 26.5289765 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 502/1000\n",
      "State[CPU, Memory] => [[69.82265653 96.54063065]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 503/1000\n",
      "State[CPU, Memory] => [[29.21879075 76.1625792 ]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 504/1000\n",
      "State[CPU, Memory] => [[66.45216416 80.85840154]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 505/1000\n",
      "State[CPU, Memory] => [[63.63479371 83.29802575]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 506/1000\n",
      "State[CPU, Memory] => [[41.19292448  8.93251042]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 507/1000\n",
      "State[CPU, Memory] => [[50.69746614 92.49431117]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 508/1000\n",
      "State[CPU, Memory] => [[57.21300489 29.98877938]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 509/1000\n",
      "State[CPU, Memory] => [[82.05116299 24.06260729]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 510/1000\n",
      "State[CPU, Memory] => [[36.04388911 47.51394744]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 511/1000\n",
      "State[CPU, Memory] => [[72.98825927 58.66853027]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 512/1000\n",
      "State[CPU, Memory] => [[48.59982721 25.2304468 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 513/1000\n",
      "State[CPU, Memory] => [[65.07165223 36.70034989]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 514/1000\n",
      "State[CPU, Memory] => [[ 9.93583954 22.05089568]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 515/1000\n",
      "State[CPU, Memory] => [[31.84772837 20.03142913]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 516/1000\n",
      "State[CPU, Memory] => [[54.84839648 13.40698632]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 517/1000\n",
      "State[CPU, Memory] => [[ 8.36005306 86.26333378]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 518/1000\n",
      "State[CPU, Memory] => [[14.51641338 41.96519238]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 519/1000\n",
      "State[CPU, Memory] => [[92.14650774 57.70017071]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 520/1000\n",
      "State[CPU, Memory] => [[61.81605853 53.21265886]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 521/1000\n",
      "State[CPU, Memory] => [[51.78669043 38.7855588 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 522/1000\n",
      "State[CPU, Memory] => [[10.48161394 24.05334738]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 523/1000\n",
      "State[CPU, Memory] => [[36.79706964 10.75911966]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 524/1000\n",
      "State[CPU, Memory] => [[82.93362562 81.8192113 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 525/1000\n",
      "State[CPU, Memory] => [[60.25307391 83.04955794]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 526/1000\n",
      "State[CPU, Memory] => [[24.69670778 51.82926766]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 527/1000\n",
      "State[CPU, Memory] => [[84.37694439 66.31988673]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 528/1000\n",
      "State[CPU, Memory] => [[72.5279641 61.2135739]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 529/1000\n",
      "State[CPU, Memory] => [[54.91728475 77.54180171]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 530/1000\n",
      "State[CPU, Memory] => [[38.76825004 82.83822207]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 531/1000\n",
      "State[CPU, Memory] => [[86.30688574 45.27840906]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 532/1000\n",
      "State[CPU, Memory] => [[30.90631566  8.54915466]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 533/1000\n",
      "State[CPU, Memory] => [[18.11319584 84.69049928]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 534/1000\n",
      "State[CPU, Memory] => [[63.68074044 84.84958104]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 535/1000\n",
      "State[CPU, Memory] => [[71.6008853  16.98578447]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 536/1000\n",
      "State[CPU, Memory] => [[60.50134099 66.00097054]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 537/1000\n",
      "State[CPU, Memory] => [[95.74095513 61.52848865]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 538/1000\n",
      "State[CPU, Memory] => [[32.40041122 98.54855078]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 539/1000\n",
      "State[CPU, Memory] => [[31.93172477 40.3152731 ]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 540/1000\n",
      "State[CPU, Memory] => [[15.31573597  3.18470922]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 541/1000\n",
      "State[CPU, Memory] => [[77.19445764 43.81453727]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 542/1000\n",
      "State[CPU, Memory] => [[ 6.62174143 46.50272452]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 543/1000\n",
      "State[CPU, Memory] => [[47.68814946 62.8133093 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 544/1000\n",
      "State[CPU, Memory] => [[72.21858938 90.43527789]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 545/1000\n",
      "State[CPU, Memory] => [[ 1.59286107 51.14418885]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 546/1000\n",
      "State[CPU, Memory] => [[51.06456018 12.32951306]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 547/1000\n",
      "State[CPU, Memory] => [[23.35705801 86.27930955]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 548/1000\n",
      "State[CPU, Memory] => [[25.96007001 71.15652026]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 549/1000\n",
      "State[CPU, Memory] => [[22.60571292 59.95747014]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 550/1000\n",
      "State[CPU, Memory] => [[82.46076164 37.73772183]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 551/1000\n",
      "State[CPU, Memory] => [[47.68061884 98.07357595]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 552/1000\n",
      "State[CPU, Memory] => [[81.52139905 84.86073677]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 553/1000\n",
      "State[CPU, Memory] => [[92.71950603 50.4614339 ]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 554/1000\n",
      "State[CPU, Memory] => [[28.22008429 88.09745839]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 555/1000\n",
      "State[CPU, Memory] => [[49.75221273 86.54974054]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 556/1000\n",
      "State[CPU, Memory] => [[16.19288313 19.14513141]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 557/1000\n",
      "State[CPU, Memory] => [[14.43685801 30.66173532]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 558/1000\n",
      "State[CPU, Memory] => [[62.16107612  8.50336233]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 559/1000\n",
      "State[CPU, Memory] => [[ 3.81473226 51.95896532]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 560/1000\n",
      "State[CPU, Memory] => [[22.60545697  6.53076712]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 561/1000\n",
      "State[CPU, Memory] => [[78.63264464  2.78596442]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 562/1000\n",
      "State[CPU, Memory] => [[70.80293728 57.72103265]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 563/1000\n",
      "State[CPU, Memory] => [[ 8.64811394 96.59504741]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 564/1000\n",
      "State[CPU, Memory] => [[52.05139598 51.23192128]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 565/1000\n",
      "State[CPU, Memory] => [[18.20291825 30.70131908]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 566/1000\n",
      "State[CPU, Memory] => [[18.45402126 39.0909505 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 567/1000\n",
      "State[CPU, Memory] => [[95.37304864  8.29903465]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 568/1000\n",
      "State[CPU, Memory] => [[ 9.35209701 74.83651377]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 569/1000\n",
      "State[CPU, Memory] => [[64.06750644 56.51661252]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 570/1000\n",
      "State[CPU, Memory] => [[10.09738303 56.26275775]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 571/1000\n",
      "State[CPU, Memory] => [[ 5.35220851 92.91888151]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 572/1000\n",
      "State[CPU, Memory] => [[20.8808784   4.74788746]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 573/1000\n",
      "State[CPU, Memory] => [[38.73733178 57.48980929]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 574/1000\n",
      "State[CPU, Memory] => [[36.66202293 23.16541695]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 575/1000\n",
      "State[CPU, Memory] => [[80.7650667  17.91097068]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 576/1000\n",
      "State[CPU, Memory] => [[34.52389533 31.55395227]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 577/1000\n",
      "State[CPU, Memory] => [[42.24393943 62.19573865]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 578/1000\n",
      "State[CPU, Memory] => [[51.96574541 36.49562342]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 579/1000\n",
      "State[CPU, Memory] => [[42.82191566  9.95710439]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 580/1000\n",
      "State[CPU, Memory] => [[28.28238383 11.86278917]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 581/1000\n",
      "State[CPU, Memory] => [[78.97016319 85.74161772]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 582/1000\n",
      "State[CPU, Memory] => [[58.28725761 57.80660371]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 583/1000\n",
      "State[CPU, Memory] => [[44.26247144 78.59951829]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 584/1000\n",
      "State[CPU, Memory] => [[23.43483955 28.92562039]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 585/1000\n",
      "State[CPU, Memory] => [[88.34777393 35.15842163]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 586/1000\n",
      "State[CPU, Memory] => [[89.74457678 99.92652017]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 587/1000\n",
      "State[CPU, Memory] => [[25.42267249 58.22427115]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 588/1000\n",
      "State[CPU, Memory] => [[10.49085701  2.67213604]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 589/1000\n",
      "State[CPU, Memory] => [[54.51676808 49.20946626]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 590/1000\n",
      "State[CPU, Memory] => [[64.50171415 16.32216089]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 591/1000\n",
      "State[CPU, Memory] => [[96.83035943  7.06588696]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 592/1000\n",
      "State[CPU, Memory] => [[91.30746576 19.00288771]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 593/1000\n",
      "State[CPU, Memory] => [[28.74575123 26.27825339]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 594/1000\n",
      "State[CPU, Memory] => [[73.49108914 93.2868976 ]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 595/1000\n",
      "State[CPU, Memory] => [[62.80070205 86.03076118]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 596/1000\n",
      "State[CPU, Memory] => [[19.99068382 43.99489912]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 597/1000\n",
      "State[CPU, Memory] => [[98.72277121 65.56734565]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 598/1000\n",
      "State[CPU, Memory] => [[92.96216071 85.96618223]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 599/1000\n",
      "State[CPU, Memory] => [[44.03442939 23.49165113]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 600/1000\n",
      "State[CPU, Memory] => [[ 2.81437782 25.12377503]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 601/1000\n",
      "State[CPU, Memory] => [[70.69180944 13.13154529]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 602/1000\n",
      "State[CPU, Memory] => [[65.08312923 22.26963479]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 603/1000\n",
      "State[CPU, Memory] => [[62.66814341 54.82545868]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 604/1000\n",
      "State[CPU, Memory] => [[12.93685599 31.34710154]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 605/1000\n",
      "State[CPU, Memory] => [[62.88546073 86.47051312]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 606/1000\n",
      "State[CPU, Memory] => [[80.40186459 39.03216423]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 607/1000\n",
      "State[CPU, Memory] => [[88.4998392 23.6234352]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 608/1000\n",
      "State[CPU, Memory] => [[52.4626569  61.26141738]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 609/1000\n",
      "State[CPU, Memory] => [[58.49409241 86.1933504 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 610/1000\n",
      "State[CPU, Memory] => [[33.41077119 75.26932925]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 611/1000\n",
      "State[CPU, Memory] => [[36.42962406 39.1662059 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 612/1000\n",
      "State[CPU, Memory] => [[41.36566246 33.62916266]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 613/1000\n",
      "State[CPU, Memory] => [[32.4025719  35.21540036]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 614/1000\n",
      "State[CPU, Memory] => [[67.16141669 61.80779212]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 615/1000\n",
      "State[CPU, Memory] => [[ 2.73302151 90.15014704]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 616/1000\n",
      "State[CPU, Memory] => [[58.78129437 92.89404477]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 617/1000\n",
      "State[CPU, Memory] => [[ 6.19706914 43.29486967]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 618/1000\n",
      "State[CPU, Memory] => [[ 3.48724722 64.49740627]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 619/1000\n",
      "State[CPU, Memory] => [[83.73421305 40.67680764]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 620/1000\n",
      "State[CPU, Memory] => [[82.78679853 53.41791651]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 621/1000\n",
      "State[CPU, Memory] => [[93.6984857   1.31932186]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 622/1000\n",
      "State[CPU, Memory] => [[11.52168582 56.38555023]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 623/1000\n",
      "State[CPU, Memory] => [[84.23249226 32.84375348]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 624/1000\n",
      "State[CPU, Memory] => [[29.42692353 68.35632638]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 625/1000\n",
      "State[CPU, Memory] => [[12.23369938 76.22977173]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 626/1000\n",
      "State[CPU, Memory] => [[ 5.15134805 21.97802409]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 627/1000\n",
      "State[CPU, Memory] => [[63.48248043 39.64892959]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 628/1000\n",
      "State[CPU, Memory] => [[71.66298996 29.35127541]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 629/1000\n",
      "State[CPU, Memory] => [[99.70266023 46.1916842 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 630/1000\n",
      "State[CPU, Memory] => [[70.89373965 48.42172784]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 631/1000\n",
      "State[CPU, Memory] => [[ 0.25746061 61.41272763]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 632/1000\n",
      "State[CPU, Memory] => [[66.10799312  1.60494409]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 633/1000\n",
      "State[CPU, Memory] => [[12.16089432 27.64435532]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 634/1000\n",
      "State[CPU, Memory] => [[65.67396989 63.27792586]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 635/1000\n",
      "State[CPU, Memory] => [[85.40063346 56.18973181]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 636/1000\n",
      "State[CPU, Memory] => [[23.71431667 43.49801165]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 637/1000\n",
      "State[CPU, Memory] => [[ 6.30122984 65.16576104]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 638/1000\n",
      "State[CPU, Memory] => [[73.14212252 98.21818705]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 639/1000\n",
      "State[CPU, Memory] => [[23.85378254 41.60594152]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 640/1000\n",
      "State[CPU, Memory] => [[66.04187736 43.04370022]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 641/1000\n",
      "State[CPU, Memory] => [[57.97700086 11.20588285]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 642/1000\n",
      "State[CPU, Memory] => [[ 3.98586951 38.56729312]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 643/1000\n",
      "State[CPU, Memory] => [[66.15454276 86.21581857]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 644/1000\n",
      "State[CPU, Memory] => [[37.41271497 31.55057251]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 645/1000\n",
      "State[CPU, Memory] => [[ 3.25299823 20.6792804 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 646/1000\n",
      "State[CPU, Memory] => [[6.77015179 6.91682366]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 647/1000\n",
      "State[CPU, Memory] => [[ 6.13132851 87.82949715]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 648/1000\n",
      "State[CPU, Memory] => [[14.8287903  21.73057686]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 649/1000\n",
      "State[CPU, Memory] => [[36.84695177 29.28412245]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 650/1000\n",
      "State[CPU, Memory] => [[68.36643255 90.01611602]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 651/1000\n",
      "State[CPU, Memory] => [[15.01112042 13.91429305]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 652/1000\n",
      "State[CPU, Memory] => [[34.75962543 23.71243103]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 653/1000\n",
      "State[CPU, Memory] => [[47.67334649 38.11600346]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 654/1000\n",
      "State[CPU, Memory] => [[18.93609034 20.96607921]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 655/1000\n",
      "State[CPU, Memory] => [[ 3.28406524 18.59024348]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 656/1000\n",
      "State[CPU, Memory] => [[24.96815322 20.0646364 ]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 657/1000\n",
      "State[CPU, Memory] => [[73.01269967  6.0651085 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 658/1000\n",
      "State[CPU, Memory] => [[49.22123252 93.31154179]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 659/1000\n",
      "State[CPU, Memory] => [[72.5812992  25.39604477]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 660/1000\n",
      "State[CPU, Memory] => [[76.32222121 32.23941667]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 661/1000\n",
      "State[CPU, Memory] => [[94.46098926 36.20255849]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 662/1000\n",
      "State[CPU, Memory] => [[64.56033282 65.68830979]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 663/1000\n",
      "State[CPU, Memory] => [[24.11362429 72.01262195]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 664/1000\n",
      "State[CPU, Memory] => [[50.10296869 41.30480525]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 665/1000\n",
      "State[CPU, Memory] => [[56.53148492 59.6851011 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 666/1000\n",
      "State[CPU, Memory] => [[29.40250778 90.44193624]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 667/1000\n",
      "State[CPU, Memory] => [[89.67290127 11.1907899 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 668/1000\n",
      "State[CPU, Memory] => [[49.99794879 62.42657462]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 669/1000\n",
      "State[CPU, Memory] => [[14.12816121 37.05785679]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 670/1000\n",
      "State[CPU, Memory] => [[83.97993665 93.08384096]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 671/1000\n",
      "State[CPU, Memory] => [[16.17407456 94.99563436]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 672/1000\n",
      "State[CPU, Memory] => [[37.70454151 19.84011713]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 673/1000\n",
      "State[CPU, Memory] => [[97.44261802 49.33180059]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 674/1000\n",
      "State[CPU, Memory] => [[82.18695846 45.1044119 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 675/1000\n",
      "State[CPU, Memory] => [[51.93813064 56.26677591]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 676/1000\n",
      "State[CPU, Memory] => [[82.18491259  2.34765449]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 677/1000\n",
      "State[CPU, Memory] => [[50.79327884 61.59017107]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 678/1000\n",
      "State[CPU, Memory] => [[11.02256436 15.46984899]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 679/1000\n",
      "State[CPU, Memory] => [[78.61361553  7.64197881]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 680/1000\n",
      "State[CPU, Memory] => [[40.08238441  6.28678013]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 681/1000\n",
      "State[CPU, Memory] => [[55.43456744 85.68627652]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 682/1000\n",
      "State[CPU, Memory] => [[68.7415093  51.21025649]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 683/1000\n",
      "State[CPU, Memory] => [[97.76696651 37.15779113]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 684/1000\n",
      "State[CPU, Memory] => [[81.83836223 92.48296651]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 685/1000\n",
      "State[CPU, Memory] => [[62.84426373 45.7514031 ]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 686/1000\n",
      "State[CPU, Memory] => [[85.58313713  9.24910769]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 687/1000\n",
      "State[CPU, Memory] => [[13.63566644 75.97459303]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 688/1000\n",
      "State[CPU, Memory] => [[32.44723978 65.09132446]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 689/1000\n",
      "State[CPU, Memory] => [[40.68765239  5.00162905]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 690/1000\n",
      "State[CPU, Memory] => [[53.74145673 70.56296122]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 691/1000\n",
      "State[CPU, Memory] => [[74.60218399 55.34239001]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 692/1000\n",
      "State[CPU, Memory] => [[27.2863235  76.09973238]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 693/1000\n",
      "State[CPU, Memory] => [[28.04330701 23.46957679]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 694/1000\n",
      "State[CPU, Memory] => [[29.06779417 77.03468113]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 695/1000\n",
      "State[CPU, Memory] => [[39.11077248 55.10226506]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 696/1000\n",
      "State[CPU, Memory] => [[24.9348464  13.38924802]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 697/1000\n",
      "State[CPU, Memory] => [[32.54363348 46.97382316]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 698/1000\n",
      "State[CPU, Memory] => [[77.12298431 54.09075171]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 699/1000\n",
      "State[CPU, Memory] => [[47.65451798 81.81318768]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 700/1000\n",
      "State[CPU, Memory] => [[97.55340287  8.67522894]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 701/1000\n",
      "State[CPU, Memory] => [[67.40032514 98.88330358]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 702/1000\n",
      "State[CPU, Memory] => [[16.16016119 75.46344182]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 703/1000\n",
      "State[CPU, Memory] => [[81.23577313 77.6250478 ]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 704/1000\n",
      "State[CPU, Memory] => [[61.10074199 38.75240846]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 705/1000\n",
      "State[CPU, Memory] => [[22.81544493 12.73261701]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 706/1000\n",
      "State[CPU, Memory] => [[62.31914018 82.57373697]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 707/1000\n",
      "State[CPU, Memory] => [[58.89386654 86.69438738]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 708/1000\n",
      "State[CPU, Memory] => [[23.66074865 86.4099762 ]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 709/1000\n",
      "State[CPU, Memory] => [[10.58737179 16.47480259]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 710/1000\n",
      "State[CPU, Memory] => [[58.19774815 76.61726149]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 711/1000\n",
      "State[CPU, Memory] => [[80.3368607  32.85960002]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 712/1000\n",
      "State[CPU, Memory] => [[14.33487955 42.45978533]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 713/1000\n",
      "State[CPU, Memory] => [[84.18643838 32.93214821]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 714/1000\n",
      "State[CPU, Memory] => [[28.58922836 70.28079397]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 715/1000\n",
      "State[CPU, Memory] => [[61.015292   55.66644351]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 716/1000\n",
      "State[CPU, Memory] => [[21.73963382 79.28830956]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 717/1000\n",
      "State[CPU, Memory] => [[29.79607755 87.3968134 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 718/1000\n",
      "State[CPU, Memory] => [[81.18443573 67.11785139]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 719/1000\n",
      "State[CPU, Memory] => [[29.51782197 10.47046636]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 720/1000\n",
      "State[CPU, Memory] => [[43.79699603  9.09323589]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 721/1000\n",
      "State[CPU, Memory] => [[75.31527799 80.33878997]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 722/1000\n",
      "State[CPU, Memory] => [[78.33745432 66.54499852]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 723/1000\n",
      "State[CPU, Memory] => [[85.92333759 82.11386255]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 724/1000\n",
      "State[CPU, Memory] => [[18.20543954 99.11315781]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 725/1000\n",
      "State[CPU, Memory] => [[52.1636984   3.72044337]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 726/1000\n",
      "State[CPU, Memory] => [[63.60556001  7.06399403]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 727/1000\n",
      "State[CPU, Memory] => [[14.56333914 32.73979505]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 728/1000\n",
      "State[CPU, Memory] => [[80.41904365 93.42966634]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 729/1000\n",
      "State[CPU, Memory] => [[45.57606244 85.78014905]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 730/1000\n",
      "State[CPU, Memory] => [[22.0094404  15.37112042]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 731/1000\n",
      "State[CPU, Memory] => [[58.62310274 27.81629504]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 732/1000\n",
      "State[CPU, Memory] => [[ 7.19006531 29.17346508]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 733/1000\n",
      "State[CPU, Memory] => [[67.61181889 89.65338774]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 734/1000\n",
      "State[CPU, Memory] => [[78.64105464 37.73312773]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 735/1000\n",
      "State[CPU, Memory] => [[ 3.1253897  44.90039583]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 736/1000\n",
      "State[CPU, Memory] => [[75.89474663 69.86340165]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 737/1000\n",
      "State[CPU, Memory] => [[62.64714209 62.88284731]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 738/1000\n",
      "State[CPU, Memory] => [[76.00324059 29.35484792]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 739/1000\n",
      "State[CPU, Memory] => [[86.84262268  0.61868433]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 740/1000\n",
      "State[CPU, Memory] => [[36.80919939 54.77368634]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 741/1000\n",
      "State[CPU, Memory] => [[19.2994971 35.5834349]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 742/1000\n",
      "State[CPU, Memory] => [[24.64010345 43.52403274]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 743/1000\n",
      "State[CPU, Memory] => [[29.2502123  62.30895149]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 744/1000\n",
      "State[CPU, Memory] => [[65.48739248 82.54169449]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 745/1000\n",
      "State[CPU, Memory] => [[ 3.69673089 11.43946663]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 746/1000\n",
      "State[CPU, Memory] => [[27.82517772 97.45899342]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 747/1000\n",
      "State[CPU, Memory] => [[52.21992077 87.87452093]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 748/1000\n",
      "State[CPU, Memory] => [[90.73197408  2.83063252]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 749/1000\n",
      "State[CPU, Memory] => [[4.15853891e+01 8.43131775e-03]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 750/1000\n",
      "State[CPU, Memory] => [[77.17671755 11.02264684]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 751/1000\n",
      "State[CPU, Memory] => [[87.79729934 23.83384381]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 752/1000\n",
      "State[CPU, Memory] => [[35.10824647 65.23917253]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 753/1000\n",
      "State[CPU, Memory] => [[69.579817   74.64363274]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 754/1000\n",
      "State[CPU, Memory] => [[53.48597574 99.51609041]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 755/1000\n",
      "State[CPU, Memory] => [[94.56074391 65.68899594]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 756/1000\n",
      "State[CPU, Memory] => [[42.61525023 63.58682209]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 757/1000\n",
      "State[CPU, Memory] => [[91.66627314 48.47654478]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 758/1000\n",
      "State[CPU, Memory] => [[38.91644835 36.55461551]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 759/1000\n",
      "State[CPU, Memory] => [[98.59434509 20.20098917]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 760/1000\n",
      "State[CPU, Memory] => [[43.70891415 44.58335482]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 761/1000\n",
      "State[CPU, Memory] => [[51.3021424  45.17984032]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 762/1000\n",
      "State[CPU, Memory] => [[30.7373483  41.44107831]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 763/1000\n",
      "State[CPU, Memory] => [[48.15435836 10.43625479]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 764/1000\n",
      "State[CPU, Memory] => [[55.83687297  2.98678286]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 765/1000\n",
      "State[CPU, Memory] => [[34.63720958 81.00976368]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 766/1000\n",
      "State[CPU, Memory] => [[89.0802197  62.50746425]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 767/1000\n",
      "State[CPU, Memory] => [[39.91663998 47.10054447]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 768/1000\n",
      "State[CPU, Memory] => [[85.42022066 81.89076368]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 769/1000\n",
      "State[CPU, Memory] => [[98.16757739 98.82673666]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 770/1000\n",
      "State[CPU, Memory] => [[ 2.58000574 34.17315907]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 771/1000\n",
      "State[CPU, Memory] => [[ 5.13651997 94.19281429]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 772/1000\n",
      "State[CPU, Memory] => [[44.86248894 19.74806433]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 773/1000\n",
      "State[CPU, Memory] => [[38.077882   83.88337094]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 774/1000\n",
      "State[CPU, Memory] => [[93.43956073 24.67408903]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 775/1000\n",
      "State[CPU, Memory] => [[83.41070247 24.67562439]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 776/1000\n",
      "State[CPU, Memory] => [[22.01840475 91.63438603]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 777/1000\n",
      "State[CPU, Memory] => [[43.22423302 86.16567098]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 778/1000\n",
      "State[CPU, Memory] => [[16.00085887 33.40738847]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 779/1000\n",
      "State[CPU, Memory] => [[24.18733717 99.58241402]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 780/1000\n",
      "State[CPU, Memory] => [[85.87899785 48.12461729]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 781/1000\n",
      "State[CPU, Memory] => [[42.70294103  5.60351548]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 782/1000\n",
      "State[CPU, Memory] => [[73.91789476 48.86498252]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 783/1000\n",
      "State[CPU, Memory] => [[23.34403187  4.82775658]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 784/1000\n",
      "State[CPU, Memory] => [[83.73626862 90.20924185]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 785/1000\n",
      "State[CPU, Memory] => [[6.78920162 7.34322556]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 786/1000\n",
      "State[CPU, Memory] => [[46.47180857 15.95961182]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 787/1000\n",
      "State[CPU, Memory] => [[70.53892867  8.59438824]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 788/1000\n",
      "State[CPU, Memory] => [[34.68523933  3.43657544]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 789/1000\n",
      "State[CPU, Memory] => [[ 8.75691759 51.51033771]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 790/1000\n",
      "State[CPU, Memory] => [[65.77894744 28.1534708 ]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 791/1000\n",
      "State[CPU, Memory] => [[61.33408756 43.1400741 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 792/1000\n",
      "State[CPU, Memory] => [[79.77488929 93.90026095]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 793/1000\n",
      "State[CPU, Memory] => [[21.05543705 83.75386506]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 794/1000\n",
      "State[CPU, Memory] => [[39.07544474 74.39851393]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 795/1000\n",
      "State[CPU, Memory] => [[68.31575824 95.91844961]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 796/1000\n",
      "State[CPU, Memory] => [[75.89230023 76.47243222]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 797/1000\n",
      "State[CPU, Memory] => [[24.06747686 19.89586956]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 798/1000\n",
      "State[CPU, Memory] => [[ 5.84708386 77.14515352]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 799/1000\n",
      "State[CPU, Memory] => [[22.69106213 58.15977816]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 800/1000\n",
      "State[CPU, Memory] => [[38.79714724 45.73722353]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 801/1000\n",
      "State[CPU, Memory] => [[98.50482408  1.17488943]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 802/1000\n",
      "State[CPU, Memory] => [[86.25157108 66.29281568]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 803/1000\n",
      "State[CPU, Memory] => [[46.19797172 96.88067296]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 804/1000\n",
      "State[CPU, Memory] => [[78.45014248  1.27154584]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 805/1000\n",
      "State[CPU, Memory] => [[63.61972902 56.48703928]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 806/1000\n",
      "State[CPU, Memory] => [[48.82959964 75.11124371]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 807/1000\n",
      "State[CPU, Memory] => [[50.53973115 18.0161536 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 808/1000\n",
      "State[CPU, Memory] => [[20.73497396 87.25059774]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 809/1000\n",
      "State[CPU, Memory] => [[47.07908104 54.76381684]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 810/1000\n",
      "State[CPU, Memory] => [[88.33623486 15.06153661]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 811/1000\n",
      "State[CPU, Memory] => [[25.68119527  6.10398246]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 812/1000\n",
      "State[CPU, Memory] => [[93.27772024 34.70918485]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 813/1000\n",
      "State[CPU, Memory] => [[70.25036739 13.76015537]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 814/1000\n",
      "State[CPU, Memory] => [[74.14686434 23.68757024]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 815/1000\n",
      "State[CPU, Memory] => [[42.99031187 86.19390212]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 816/1000\n",
      "State[CPU, Memory] => [[11.65632176 18.8941709 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 817/1000\n",
      "State[CPU, Memory] => [[34.91858252 20.62584517]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 818/1000\n",
      "State[CPU, Memory] => [[83.68872849 46.23495648]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 819/1000\n",
      "State[CPU, Memory] => [[80.05536645 28.53586214]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 820/1000\n",
      "State[CPU, Memory] => [[29.81105777 76.14434435]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 821/1000\n",
      "State[CPU, Memory] => [[2.67655242 3.30428555]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 822/1000\n",
      "State[CPU, Memory] => [[39.57700164 56.33288286]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 823/1000\n",
      "State[CPU, Memory] => [[19.21674699  6.03371561]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 824/1000\n",
      "State[CPU, Memory] => [[4.34083334 3.30300933]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 825/1000\n",
      "State[CPU, Memory] => [[33.53271039 43.70567588]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 826/1000\n",
      "State[CPU, Memory] => [[34.16769214 59.94200739]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 827/1000\n",
      "State[CPU, Memory] => [[44.76297892 81.8901099 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 828/1000\n",
      "State[CPU, Memory] => [[ 9.35291527 66.91945507]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 829/1000\n",
      "State[CPU, Memory] => [[85.75700337 29.35873098]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 830/1000\n",
      "State[CPU, Memory] => [[47.11929746 56.65978392]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 831/1000\n",
      "State[CPU, Memory] => [[35.48970058 72.784734  ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 832/1000\n",
      "State[CPU, Memory] => [[90.38866064 96.06177732]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 833/1000\n",
      "State[CPU, Memory] => [[75.14792647 33.38209233]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 834/1000\n",
      "State[CPU, Memory] => [[31.63522567 20.31274537]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 835/1000\n",
      "State[CPU, Memory] => [[35.46283815 77.56749905]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 836/1000\n",
      "State[CPU, Memory] => [[19.79224542 21.1628189 ]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 837/1000\n",
      "State[CPU, Memory] => [[40.55499059 14.83859656]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 838/1000\n",
      "State[CPU, Memory] => [[66.00249167 16.15178561]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 839/1000\n",
      "State[CPU, Memory] => [[41.060094   86.13150272]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 840/1000\n",
      "State[CPU, Memory] => [[52.02936319 63.05153882]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 841/1000\n",
      "State[CPU, Memory] => [[40.16175731 19.32383944]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 842/1000\n",
      "State[CPU, Memory] => [[ 5.38755143 25.16401236]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 843/1000\n",
      "State[CPU, Memory] => [[98.49364588 33.44906509]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 844/1000\n",
      "State[CPU, Memory] => [[64.23914271 47.45695274]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 845/1000\n",
      "State[CPU, Memory] => [[60.20538559 53.87743515]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 846/1000\n",
      "State[CPU, Memory] => [[81.98086505 22.91126957]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 847/1000\n",
      "State[CPU, Memory] => [[35.80959118 28.55279763]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 848/1000\n",
      "State[CPU, Memory] => [[74.83555114 89.16707123]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 849/1000\n",
      "State[CPU, Memory] => [[72.96225948 26.47958516]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 850/1000\n",
      "State[CPU, Memory] => [[93.3563906  82.22698856]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 851/1000\n",
      "State[CPU, Memory] => [[88.82818524 56.9013667 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 852/1000\n",
      "State[CPU, Memory] => [[56.33317356 12.44247685]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 853/1000\n",
      "State[CPU, Memory] => [[37.08707278 84.2881503 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 854/1000\n",
      "State[CPU, Memory] => [[64.28674092 94.94785009]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 855/1000\n",
      "State[CPU, Memory] => [[65.2192057  50.63026836]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 856/1000\n",
      "State[CPU, Memory] => [[21.84920817 29.54272942]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 857/1000\n",
      "State[CPU, Memory] => [[31.96951595 43.28893861]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 858/1000\n",
      "State[CPU, Memory] => [[20.47115767 40.8785762 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 859/1000\n",
      "State[CPU, Memory] => [[86.14778697 24.27827887]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 860/1000\n",
      "State[CPU, Memory] => [[22.37935948 95.75104636]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 861/1000\n",
      "State[CPU, Memory] => [[40.5055727  40.92276551]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 862/1000\n",
      "State[CPU, Memory] => [[17.42921136 90.96740759]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 863/1000\n",
      "State[CPU, Memory] => [[46.5736723  21.89065835]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 864/1000\n",
      "State[CPU, Memory] => [[76.52805401 82.31574604]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 865/1000\n",
      "State[CPU, Memory] => [[74.51935288  3.53406791]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 866/1000\n",
      "State[CPU, Memory] => [[94.94760561  5.61194907]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 867/1000\n",
      "State[CPU, Memory] => [[22.06041815 36.90906428]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 868/1000\n",
      "State[CPU, Memory] => [[88.39782125 22.59965912]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 869/1000\n",
      "State[CPU, Memory] => [[18.62353985 51.3776565 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 870/1000\n",
      "State[CPU, Memory] => [[18.45103306 45.04471799]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 871/1000\n",
      "State[CPU, Memory] => [[98.41326816 47.57836054]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 872/1000\n",
      "State[CPU, Memory] => [[85.03510062 50.27523566]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 873/1000\n",
      "State[CPU, Memory] => [[80.96602612 11.60860537]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 874/1000\n",
      "State[CPU, Memory] => [[ 0.98373318 75.87432238]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 875/1000\n",
      "State[CPU, Memory] => [[32.22413976 47.09790309]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 876/1000\n",
      "State[CPU, Memory] => [[40.54997673  3.24821186]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 877/1000\n",
      "State[CPU, Memory] => [[70.57707113 68.61883839]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 878/1000\n",
      "State[CPU, Memory] => [[70.15480228 89.11380542]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 879/1000\n",
      "State[CPU, Memory] => [[77.27580846 42.08107689]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 880/1000\n",
      "State[CPU, Memory] => [[20.10827572 46.93007089]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 881/1000\n",
      "State[CPU, Memory] => [[23.62389317 64.39732607]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 882/1000\n",
      "State[CPU, Memory] => [[43.33616447 59.21805842]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 883/1000\n",
      "State[CPU, Memory] => [[97.27795204 79.67442753]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 884/1000\n",
      "State[CPU, Memory] => [[98.09718229 68.86609901]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 885/1000\n",
      "State[CPU, Memory] => [[52.85160193 69.7560776 ]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 886/1000\n",
      "State[CPU, Memory] => [[82.44981222 93.6035178 ]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 887/1000\n",
      "State[CPU, Memory] => [[80.36588786 13.00411108]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 888/1000\n",
      "State[CPU, Memory] => [[87.92969334 73.49357172]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 889/1000\n",
      "State[CPU, Memory] => [[47.17803634 25.8043919 ]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 890/1000\n",
      "State[CPU, Memory] => [[57.34276715 80.46249009]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 891/1000\n",
      "State[CPU, Memory] => [[ 1.29117565 87.62049965]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 892/1000\n",
      "State[CPU, Memory] => [[10.00035431 63.16598816]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 893/1000\n",
      "State[CPU, Memory] => [[72.80536852 65.54676238]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 894/1000\n",
      "State[CPU, Memory] => [[39.22261188 66.11951491]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 895/1000\n",
      "State[CPU, Memory] => [[72.24313615 26.26331912]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 896/1000\n",
      "State[CPU, Memory] => [[45.67772923 40.96229621]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 897/1000\n",
      "State[CPU, Memory] => [[ 3.22247596 64.85234953]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 898/1000\n",
      "State[CPU, Memory] => [[46.17360259 68.76357206]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 899/1000\n",
      "State[CPU, Memory] => [[58.1270544  74.33568399]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 900/1000\n",
      "State[CPU, Memory] => [[54.52837586 19.27076216]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 901/1000\n",
      "State[CPU, Memory] => [[32.40816767 94.111743  ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 902/1000\n",
      "State[CPU, Memory] => [[16.96854694 78.2374803 ]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 903/1000\n",
      "State[CPU, Memory] => [[90.64405259 53.63832533]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 904/1000\n",
      "State[CPU, Memory] => [[ 2.62491507 77.02645568]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 905/1000\n",
      "State[CPU, Memory] => [[23.17333876 99.61412096]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 906/1000\n",
      "State[CPU, Memory] => [[77.87565005 93.46815069]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 907/1000\n",
      "State[CPU, Memory] => [[75.39508881 86.77371171]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 908/1000\n",
      "State[CPU, Memory] => [[15.42618209 56.79551403]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 909/1000\n",
      "State[CPU, Memory] => [[79.49762176 18.17858019]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 910/1000\n",
      "State[CPU, Memory] => [[82.77245632 25.81919737]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 911/1000\n",
      "State[CPU, Memory] => [[88.32632834 68.54829769]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 912/1000\n",
      "State[CPU, Memory] => [[ 2.1789549  45.39784821]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 913/1000\n",
      "State[CPU, Memory] => [[86.14413255 64.3680766 ]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 914/1000\n",
      "State[CPU, Memory] => [[ 2.59240468 12.56747011]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 915/1000\n",
      "State[CPU, Memory] => [[77.99911985 21.26335566]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 916/1000\n",
      "State[CPU, Memory] => [[34.55157051  7.05784408]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 917/1000\n",
      "State[CPU, Memory] => [[61.25442983 58.21841909]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 918/1000\n",
      "State[CPU, Memory] => [[ 2.90804095 15.71652791]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 919/1000\n",
      "State[CPU, Memory] => [[63.97584337 78.48268158]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 920/1000\n",
      "State[CPU, Memory] => [[40.81543441  7.76856623]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 921/1000\n",
      "State[CPU, Memory] => [[22.698959   16.91031067]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 922/1000\n",
      "State[CPU, Memory] => [[33.2187889  41.85847118]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 923/1000\n",
      "State[CPU, Memory] => [[83.29686123 40.6749098 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 924/1000\n",
      "State[CPU, Memory] => [[51.53283227 15.63064435]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 925/1000\n",
      "State[CPU, Memory] => [[40.32237968 98.91100513]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 926/1000\n",
      "State[CPU, Memory] => [[28.83759186 61.37929618]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 927/1000\n",
      "State[CPU, Memory] => [[40.00277407 41.04296243]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 928/1000\n",
      "State[CPU, Memory] => [[52.99125694 92.53671928]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 929/1000\n",
      "State[CPU, Memory] => [[71.69299047 66.98795601]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 930/1000\n",
      "State[CPU, Memory] => [[51.76937191 28.01965269]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 931/1000\n",
      "State[CPU, Memory] => [[72.62961948 71.4723679 ]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 932/1000\n",
      "State[CPU, Memory] => [[ 1.11843444 12.47470555]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 933/1000\n",
      "State[CPU, Memory] => [[20.05153511 99.99346402]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 934/1000\n",
      "State[CPU, Memory] => [[23.07872956 12.30840569]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 935/1000\n",
      "State[CPU, Memory] => [[89.55928344 77.66267324]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 936/1000\n",
      "State[CPU, Memory] => [[ 4.43297602 12.1184908 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 937/1000\n",
      "State[CPU, Memory] => [[71.1580075   1.66122229]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 938/1000\n",
      "State[CPU, Memory] => [[92.4541362  90.00920103]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 939/1000\n",
      "State[CPU, Memory] => [[60.59383593 47.98496668]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 940/1000\n",
      "State[CPU, Memory] => [[47.73687755 23.37118116]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 941/1000\n",
      "State[CPU, Memory] => [[31.66798503 30.11128341]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 942/1000\n",
      "State[CPU, Memory] => [[17.05527458 42.64395204]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 943/1000\n",
      "State[CPU, Memory] => [[47.26833695 46.78343839]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 944/1000\n",
      "State[CPU, Memory] => [[37.33145374 92.21268182]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 945/1000\n",
      "State[CPU, Memory] => [[ 0.35982765 45.78656541]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 946/1000\n",
      "State[CPU, Memory] => [[82.64373076  9.76113018]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 947/1000\n",
      "State[CPU, Memory] => [[82.12407707 63.34284156]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 948/1000\n",
      "State[CPU, Memory] => [[65.0389857  76.26826774]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 949/1000\n",
      "State[CPU, Memory] => [[82.24354471 31.56981073]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 950/1000\n",
      "State[CPU, Memory] => [[12.01796016 15.05298761]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 951/1000\n",
      "State[CPU, Memory] => [[63.15233682 64.78978628]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 952/1000\n",
      "State[CPU, Memory] => [[12.62890093 45.18712982]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 953/1000\n",
      "State[CPU, Memory] => [[85.78722754 18.78749768]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 954/1000\n",
      "State[CPU, Memory] => [[97.56272287 41.44169707]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 955/1000\n",
      "State[CPU, Memory] => [[62.42200846 81.0635351 ]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 956/1000\n",
      "State[CPU, Memory] => [[77.0109427  80.24656829]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 957/1000\n",
      "State[CPU, Memory] => [[68.17211862 94.56933894]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 958/1000\n",
      "State[CPU, Memory] => [[91.98688497 46.13778678]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 959/1000\n",
      "State[CPU, Memory] => [[74.30249039 78.69527726]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 960/1000\n",
      "State[CPU, Memory] => [[15.54896676 59.32402954]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 961/1000\n",
      "State[CPU, Memory] => [[15.59051892 24.13198158]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 962/1000\n",
      "State[CPU, Memory] => [[12.63773716 16.29570581]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 963/1000\n",
      "State[CPU, Memory] => [[53.63192433 28.65742368]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 964/1000\n",
      "State[CPU, Memory] => [[86.10550803 21.04043714]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 965/1000\n",
      "State[CPU, Memory] => [[ 6.67823963 54.34260911]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 966/1000\n",
      "State[CPU, Memory] => [[59.17646675 34.90175282]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 967/1000\n",
      "State[CPU, Memory] => [[27.81712703 74.010352  ]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 968/1000\n",
      "State[CPU, Memory] => [[64.86381892 40.74711952]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 969/1000\n",
      "State[CPU, Memory] => [[24.42297001 48.41301132]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 970/1000\n",
      "State[CPU, Memory] => [[29.86903871 90.04148646]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:5, Recipient Reward:100\n",
      "episode: 971/1000\n",
      "State[CPU, Memory] => [[60.78614368 17.55871923]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 972/1000\n",
      "State[CPU, Memory] => [[19.91946221 83.0794201 ]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 973/1000\n",
      "State[CPU, Memory] => [[90.67704862  4.9221399 ]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 974/1000\n",
      "State[CPU, Memory] => [[98.52905189 51.1905911 ]]\n",
      "Action:4, Sender Reward:600\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 975/1000\n",
      "State[CPU, Memory] => [[72.20505995 16.54993511]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 976/1000\n",
      "State[CPU, Memory] => [[56.41726806 31.20504382]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 977/1000\n",
      "State[CPU, Memory] => [[84.78037174 43.19283339]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 978/1000\n",
      "State[CPU, Memory] => [[44.15488305 75.10805224]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 979/1000\n",
      "State[CPU, Memory] => [[44.86073543 51.23509133]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 980/1000\n",
      "State[CPU, Memory] => [[59.10584021 51.79472968]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 981/1000\n",
      "State[CPU, Memory] => [[ 9.95096649 12.28464888]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 982/1000\n",
      "State[CPU, Memory] => [[38.95479207 19.58041749]]\n",
      "Action:5, Sender Reward:500\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 983/1000\n",
      "State[CPU, Memory] => [[35.03136997 38.51054225]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 984/1000\n",
      "State[CPU, Memory] => [[37.39020014 53.78227066]]\n",
      "Action:2, Sender Reward:800\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 985/1000\n",
      "State[CPU, Memory] => [[10.86876551 82.91676191]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 986/1000\n",
      "State[CPU, Memory] => [[27.69645876 35.22614584]]\n",
      "Action:8, Sender Reward:200\n",
      "Action:2, Recipient Reward:100\n",
      "episode: 987/1000\n",
      "State[CPU, Memory] => [[25.2997094  2.6013073]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 988/1000\n",
      "State[CPU, Memory] => [[99.76207634 16.47128977]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 989/1000\n",
      "State[CPU, Memory] => [[69.30325764 94.60315374]]\n",
      "Action:7, Sender Reward:300\n",
      "Action:0, Recipient Reward:100\n",
      "episode: 990/1000\n",
      "State[CPU, Memory] => [[42.58191878 68.35350829]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 991/1000\n",
      "State[CPU, Memory] => [[64.64123087 60.68824318]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 992/1000\n",
      "State[CPU, Memory] => [[91.68068504 94.41655493]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 993/1000\n",
      "State[CPU, Memory] => [[13.34463422 82.82407202]]\n",
      "Action:0, Sender Reward:1000\n",
      "Action:6, Recipient Reward:100\n",
      "episode: 994/1000\n",
      "State[CPU, Memory] => [[35.99402217 51.00233745]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:7, Recipient Reward:100\n",
      "episode: 995/1000\n",
      "State[CPU, Memory] => [[58.29325165 57.68563893]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:3, Recipient Reward:100\n",
      "episode: 996/1000\n",
      "State[CPU, Memory] => [[98.09198363 75.5019101 ]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:4, Recipient Reward:100\n",
      "episode: 997/1000\n",
      "State[CPU, Memory] => [[17.84574467 68.72530144]]\n",
      "Action:3, Sender Reward:700\n",
      "Action:1, Recipient Reward:100\n",
      "episode: 998/1000\n",
      "State[CPU, Memory] => [[55.98952525 95.78943373]]\n",
      "Action:1, Sender Reward:900\n",
      "Action:8, Recipient Reward:-2000\n",
      "episode: 999/1000\n",
      "State[CPU, Memory] => [[67.73521501 60.89160204]]\n",
      "Action:6, Sender Reward:400\n",
      "Action:1, Recipient Reward:100\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "for e in range(n_episodes): # iterate over new episodes of the game\n",
    "    print(\"episode: {}/{}\".format(e,n_episodes))\n",
    "    \n",
    "    state = env.reset() # reset state at start of each new episode of the game    \n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    print(\"State[CPU, Memory] => {}\".format(state))\n",
    "    \n",
    "    sender_action = sender_agent.act(state) # action is to select to migrate out some of the VMs from 0 to 8\n",
    "    sender_reward = env.reward_out[sender_action]\n",
    "    print(\"Sender Action:{}, Sender Reward:{}\".format(sender_action,sender_reward))\n",
    "    \n",
    "    recipient_action = recipient_agent.act(state) # action is to select to migrate out some of the VMs from 0 to 8\n",
    "    recipient_reward = env.reward_in[recipient_action]\n",
    "    print(\"Recipient Action:{}, Recipient Reward:{}\".format(recipient_action,recipient_reward))\n",
    "    \n",
    "#     next_state, reward, done, _ = env.step(action) # agent interacts with env, gets feedback; 4 state data points, e.g., pole angle, cart position        \n",
    "#     reward = reward if not done else -10 # reward +1 for each additional frame with pole upright        \n",
    "#     next_state = np.reshape(next_state, [1, state_size])\n",
    "#     agent.remember(state, action, reward, next_state, done) # remember the previous timestep's state, actions, reward, etc.        \n",
    "#     state = next_state # set \"current state\" for upcoming iteration to the current next state \n",
    "    \n",
    "#     for time in range(5000):  # time represents a frame of the game; goal is to keep pole upright as long as possible up to range, e.g., 500 or 5000 timesteps\n",
    "#         env.render()\n",
    "#         action = agent.act(state) # action is either 0 or 1 (move cart left or right); decide on one or other here\n",
    "#         next_state, reward, done, _ = env.step(action) # agent interacts with env, gets feedback; 4 state data points, e.g., pole angle, cart position        \n",
    "#         reward = reward if not done else -10 # reward +1 for each additional frame with pole upright        \n",
    "#         next_state = np.reshape(next_state, [1, state_size])\n",
    "#         agent.remember(state, action, reward, next_state, done) # remember the previous timestep's state, actions, reward, etc.        \n",
    "#         state = next_state # set \"current state\" for upcoming iteration to the current next state        \n",
    "#         if done: # episode ends if agent drops pole or we reach timestep 5000\n",
    "#             print(\"episode: {}/{}, score: {}, e: {:.2}\" # print the episode's score and agent's epsilon\n",
    "#                   .format(e, n_episodes, time, agent.epsilon))\n",
    "#             break # exit loop\n",
    "#     if len(agent.memory) > batch_size:\n",
    "#         agent.replay(batch_size) # train the agent by replaying the experiences of the episode\n",
    "    if e % 50 == 0:\n",
    "        sender_agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")\n",
    "        recipient_agent.save(output_dir + \"weights_\" + '{:04d}'.format(e) + \".hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
